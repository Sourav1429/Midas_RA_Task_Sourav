# Midas_RA_Task_Sourav
The record of each task is taken in jupyter notebook. 
My assumption was that the datasets are stored in D drive under a folder datasets having a subfolder IIIT_D

Thus, the path becomes "D:\datasets\IIIT_D\<files_given>"

All the experiments log along with the accuracy and the steps taken along with the detailed thought process has been shown in the (.ipynb) files.

The given task had 3 subparts. I have created independent submits for each subpart.

On the whole I did not create any link in between any files by importing them into other parts.

The Modules used are namely

OS
tensorflow -----> Keras API
numpy
tqdm
openCV
Matplotlib
and train_test_split from sklearn

So to run these files these modules are mandatory

a) In subpart 1 I have followed a CNN approach as demanded in the question
b) For this subpart followed normal ANN.
c) ANN again.

A file named failed_log_subpart_1 is given to show the failed approaches taken to solve the problem.
However for subpart 2 and 3. I did not maintain a separate notebook and kept everything in one place due to limited time.

Help Taken from:
I took help from certain sources as mentioned below
a) TRAINING DEEP NEURAL-NETWORKS USING A NOISE ADAPTATION LAYER paper by Jacob Goldberger & Ehud Ben-Reuven Engineering Faculty, Bar-Ilan University, published as a conference paper at ICLR 2017
b) Bekker and J. Goldberger. Training deep neural-networks based on unreliable labels. In IEEE Int.l Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2682â€“2686, 2016.
c) https://github.com/udibr/noisy_labels
d) www.machinelearningmastery.com by Jason Brownlee
e) www.google.com
f) https://keras.io/guides/functional_api/
