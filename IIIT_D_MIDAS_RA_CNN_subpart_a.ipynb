{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the necessary files and modules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step to CNN model starts with the listing of all the important modules.\n",
    "1) cv2: Used for importing images and converting it into numpy array\n",
    "2) Matplotlib: Since in Jupyter notebook we cannot use cv2.imshow() as it creates a small issue. Hence using imshow() in matplotlib.pyplot\n",
    "    for displaying the image\n",
    "3) tensorflow: to call the backend or suppoting Keras API.\n",
    "4) Dense, Dropout, Activation,Flatten: Creating the network used for desigining the CNN architecture\n",
    "5) OS: To locate files after downloading the file, from local machine\n",
    "6) tqdm: To give a professional loading info and look when the images are being loaded from local machine\n",
    "7) numpy: For reshaping and creating arrays for numerical calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D,Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: Defining the path where the dataset is stored in local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D://datasets//IIIT_D//train\";#path where the dataset is downloaded in my machine\n",
    "fol=os.listdir(path)#list of files in the 'train' folder in the location D:\\datasets\\IIIT_D\\train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps include a) create a bag of symbols so that we can assign a unique number to each symbol as below\n",
    "b) Also define a one_hot() which will create a one hot vector. Although for now it creates a list of zeros to conquer the dimensionality\n",
    "issue faced during the training. But will be later converted into a numpy array.\n",
    "So the vector is of size 62(62 unique characters in the dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=list(),list();#define empty list for acquiring training and testing data\n",
    "size=len(fol);\n",
    "#next create a bag of symbols which will be a dictionary\n",
    "bag={0:'0',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'A',11:'B',12:'C',13:'D',14:'E',15:'F',16:'G',17:'H',\n",
    "    18:'I',19:'J',20:'K',21:'L',22:'M',23:'N',24:'O',25:'P',26:'Q',27:'R',28:'S',29:'T',30:'U',31:'V',32:'W',33:'X',34:'Y',\n",
    "    35:'Z',36:'a',37:'b',38:'c',39:'d',40:'e',41:'f',42:'g',43:'h',44:'i',45:'j',46:'k',47:'l',48:'m',\n",
    "     49:'n',50:'o',51:'p',52:'q',53:'r',54:'s',55:'t',56:'u',57:'v',58:'w',59:'x',60:'y',61:'z'};\n",
    "#define our one_hot vector\n",
    "def one_hot(val,size):\n",
    "    a=np.array([0]*size);\n",
    "    a[val]=1;\n",
    "    return a;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: Accessing the dataset from the local machine in X and y lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first we create a list of all the files in the 'path' mentioned above. Also keep a track of the position of each file using a \n",
    "counter in form of the variable 'val'. Then the folders under the 'path' mentioned above are explored one by one which contains the pictures.\n",
    "Here only one thing to be noted which can change the full results is the order of the files must comply with the bag of symbols\n",
    "i.e. the first file namely Sample001 in the given dataset which is actually pictures of '0' written in handwritten must comply \n",
    "with the first symbol in our bag of symbol which is '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [01:53,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for val,i in tqdm(enumerate(fol)):\n",
    "    path_n=os.path.join(path,i);\n",
    "    for img_n in os.listdir(path_n):\n",
    "        img=cv2.imread(os.path.join(path_n,img_n),cv2.IMREAD_GRAYSCALE)/255#normalize by dividing by 255 for better results.\n",
    "        X.append((np.reshape(cv2.resize(img,(50,50)),(50,50,1))))#initially we obtained a 2d array. In order to fit it in our keras CNN model, we had to convert it into a 3d model. Also the image is downsized to avoid OOM (Out of Memory) exception\n",
    "        y.append(one_hot(val,size))#store our results by converting it into a one-hot vector. Here the enumerate () returning counter val palys a very important role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is splitted into training and cross validation sets. Cross validation size 15% of total data. It aids our results and gives a genuine boost\n",
    "in our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.15, random_state=42)\n",
    "X_train_arr=np.array(X_train)\n",
    "X_val_arr=np.array(X_val)\n",
    "y_train_arr=np.array(y_train)\n",
    "y_val_arr=np.array(y_val)\n",
    "_,h,w,d=X_train_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CNN model the feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All set and done with the processing. Lets now create a training CNN network. After lots of optimization I have narrowed it down \n",
    "to the below network. It is a sequential model Cosisting of 2 Convolution layer following which we have a MaxPooling layer to \n",
    "pull out the maximum value of each 2x2 kernel and use pass it to the next layer. To avoid plagiarism I have used my surname as the variable.\n",
    "Although some keywords were manditory to use and could not help there. Ok as we can in the summary below, it gives us a rough idea of the feed forward network.\n",
    "Trainable parameters mean the weights and bias values that are initially assumed to be random values and are to be optimized later during the subsequent epochs.\n",
    "The Keras model has taken care of the backpropagation training process for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganguly = Sequential()\n",
    "ganguly.add(Conv2D(124, kernel_size=(3, 3), activation='relu', input_shape=(h,w,d)))\n",
    "ganguly.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "ganguly.add(Conv2D(248, kernel_size=(3, 3), activation='relu'))\n",
    "ganguly.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "ganguly.add(Conv2D(400, kernel_size=(3, 3), activation='relu'))\n",
    "ganguly.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "ganguly.add(Flatten())\n",
    "ganguly.add(Dense(248, activation='relu'))\n",
    "ganguly.add(Dense(124, activation='relu'))\n",
    "ganguly.add(Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 124)       1240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 124)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 248)       277016    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 248)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 400)         893200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 400)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 248)               1587448   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 124)               30876     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 62)                7750      \n",
      "=================================================================\n",
      "Total params: 2,797,530\n",
      "Trainable params: 2,797,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ganguly.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and compiling the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our next step is just use the above network to train our value. Now to measure the loss we use cross_entropy and optimze it with Adam's optimization.\n",
    "Finally feed the value with traing data and expected results of the data and cross validating against X_val_arr and y_val_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2108 samples, validate on 372 samples\n",
      "Epoch 1/10\n",
      "2108/2108 [==============================] - ETA: 17:43 - loss: 4.1296 - acc: 0.0000e+ - ETA: 8:45 - loss: 4.1261 - acc: 0.0000e+00 - ETA: 5:46 - loss: 4.1646 - acc: 0.0000e+0 - ETA: 4:16 - loss: 4.1618 - acc: 0.0078    - ETA: 3:22 - loss: 4.1484 - acc: 0.018 - ETA: 2:46 - loss: 4.1514 - acc: 0.015 - ETA: 2:20 - loss: 4.1491 - acc: 0.017 - ETA: 2:01 - loss: 4.1454 - acc: 0.019 - ETA: 1:46 - loss: 4.1447 - acc: 0.020 - ETA: 1:34 - loss: 4.1431 - acc: 0.025 - ETA: 1:24 - loss: 4.1409 - acc: 0.025 - ETA: 1:17 - loss: 4.1406 - acc: 0.023 - ETA: 1:10 - loss: 4.1391 - acc: 0.021 - ETA: 1:04 - loss: 4.1386 - acc: 0.020 - ETA: 59s - loss: 4.1371 - acc: 0.020 - ETA: 55s - loss: 4.1358 - acc: 0.02 - ETA: 51s - loss: 4.1358 - acc: 0.02 - ETA: 47s - loss: 4.1368 - acc: 0.02 - ETA: 44s - loss: 4.1377 - acc: 0.01 - ETA: 42s - loss: 4.1378 - acc: 0.01 - ETA: 39s - loss: 4.1369 - acc: 0.01 - ETA: 37s - loss: 4.1366 - acc: 0.01 - ETA: 34s - loss: 4.1362 - acc: 0.01 - ETA: 32s - loss: 4.1359 - acc: 0.01 - ETA: 31s - loss: 4.1357 - acc: 0.01 - ETA: 29s - loss: 4.1355 - acc: 0.01 - ETA: 27s - loss: 4.1353 - acc: 0.01 - ETA: 26s - loss: 4.1349 - acc: 0.01 - ETA: 24s - loss: 4.1347 - acc: 0.01 - ETA: 23s - loss: 4.1345 - acc: 0.01 - ETA: 22s - loss: 4.1342 - acc: 0.01 - ETA: 21s - loss: 4.1341 - acc: 0.01 - ETA: 20s - loss: 4.1339 - acc: 0.01 - ETA: 19s - loss: 4.1337 - acc: 0.01 - ETA: 18s - loss: 4.1335 - acc: 0.01 - ETA: 17s - loss: 4.1334 - acc: 0.01 - ETA: 16s - loss: 4.1331 - acc: 0.01 - ETA: 15s - loss: 4.1330 - acc: 0.01 - ETA: 14s - loss: 4.1326 - acc: 0.01 - ETA: 13s - loss: 4.1323 - acc: 0.01 - ETA: 12s - loss: 4.1314 - acc: 0.01 - ETA: 12s - loss: 4.1306 - acc: 0.01 - ETA: 11s - loss: 4.1294 - acc: 0.01 - ETA: 10s - loss: 4.1307 - acc: 0.01 - ETA: 9s - loss: 4.1332 - acc: 0.0181 - ETA: 9s - loss: 4.1325 - acc: 0.018 - ETA: 8s - loss: 4.1329 - acc: 0.018 - ETA: 8s - loss: 4.1325 - acc: 0.018 - ETA: 7s - loss: 4.1323 - acc: 0.018 - ETA: 6s - loss: 4.1320 - acc: 0.019 - ETA: 6s - loss: 4.1318 - acc: 0.019 - ETA: 5s - loss: 4.1316 - acc: 0.019 - ETA: 5s - loss: 4.1313 - acc: 0.020 - ETA: 4s - loss: 4.1311 - acc: 0.019 - ETA: 4s - loss: 4.1308 - acc: 0.020 - ETA: 3s - loss: 4.1304 - acc: 0.020 - ETA: 3s - loss: 4.1303 - acc: 0.020 - ETA: 3s - loss: 4.1299 - acc: 0.020 - ETA: 2s - loss: 4.1299 - acc: 0.020 - ETA: 2s - loss: 4.1295 - acc: 0.020 - ETA: 1s - loss: 4.1289 - acc: 0.021 - ETA: 1s - loss: 4.1287 - acc: 0.020 - ETA: 1s - loss: 4.1284 - acc: 0.020 - ETA: 0s - loss: 4.1276 - acc: 0.021 - ETA: 0s - loss: 4.1261 - acc: 0.022 - 25s 12ms/step - loss: 4.1250 - acc: 0.0228 - val_loss: 4.0424 - val_acc: 0.0188\n",
      "Epoch 2/10\n",
      "2108/2108 [==============================] - ETA: 3s - loss: 4.0118 - acc: 0.062 - ETA: 3s - loss: 4.0686 - acc: 0.031 - ETA: 3s - loss: 4.0205 - acc: 0.041 - ETA: 5s - loss: 3.9950 - acc: 0.046 - ETA: 6s - loss: 3.9622 - acc: 0.050 - ETA: 6s - loss: 3.9542 - acc: 0.041 - ETA: 6s - loss: 3.9314 - acc: 0.044 - ETA: 6s - loss: 3.9059 - acc: 0.058 - ETA: 6s - loss: 3.9128 - acc: 0.055 - ETA: 6s - loss: 3.9147 - acc: 0.050 - ETA: 6s - loss: 3.9081 - acc: 0.056 - ETA: 6s - loss: 3.8916 - acc: 0.059 - ETA: 6s - loss: 3.8875 - acc: 0.060 - ETA: 6s - loss: 3.8821 - acc: 0.062 - ETA: 6s - loss: 3.8644 - acc: 0.064 - ETA: 6s - loss: 3.8689 - acc: 0.066 - ETA: 6s - loss: 3.8573 - acc: 0.071 - ETA: 6s - loss: 3.8449 - acc: 0.072 - ETA: 6s - loss: 3.8279 - acc: 0.074 - ETA: 5s - loss: 3.8191 - acc: 0.073 - ETA: 5s - loss: 3.8004 - acc: 0.077 - ETA: 5s - loss: 3.8040 - acc: 0.076 - ETA: 5s - loss: 3.7931 - acc: 0.080 - ETA: 5s - loss: 3.7878 - acc: 0.079 - ETA: 5s - loss: 3.7923 - acc: 0.078 - ETA: 5s - loss: 3.7876 - acc: 0.079 - ETA: 5s - loss: 3.7856 - acc: 0.078 - ETA: 4s - loss: 3.7815 - acc: 0.077 - ETA: 4s - loss: 3.7831 - acc: 0.077 - ETA: 4s - loss: 3.7773 - acc: 0.080 - ETA: 4s - loss: 3.7603 - acc: 0.082 - ETA: 4s - loss: 3.7632 - acc: 0.080 - ETA: 4s - loss: 3.7524 - acc: 0.082 - ETA: 3s - loss: 3.7440 - acc: 0.083 - ETA: 3s - loss: 3.7345 - acc: 0.085 - ETA: 3s - loss: 3.7297 - acc: 0.085 - ETA: 3s - loss: 3.7223 - acc: 0.087 - ETA: 3s - loss: 3.7210 - acc: 0.086 - ETA: 3s - loss: 3.7140 - acc: 0.085 - ETA: 3s - loss: 3.7123 - acc: 0.084 - ETA: 3s - loss: 3.7076 - acc: 0.084 - ETA: 3s - loss: 3.6942 - acc: 0.085 - ETA: 2s - loss: 3.6824 - acc: 0.087 - ETA: 2s - loss: 3.6731 - acc: 0.087 - ETA: 2s - loss: 3.6686 - acc: 0.088 - ETA: 2s - loss: 3.6624 - acc: 0.088 - ETA: 2s - loss: 3.6664 - acc: 0.088 - ETA: 2s - loss: 3.6636 - acc: 0.089 - ETA: 2s - loss: 3.6631 - acc: 0.089 - ETA: 2s - loss: 3.6579 - acc: 0.090 - ETA: 1s - loss: 3.6499 - acc: 0.093 - ETA: 1s - loss: 3.6390 - acc: 0.095 - ETA: 1s - loss: 3.6353 - acc: 0.096 - ETA: 1s - loss: 3.6260 - acc: 0.098 - ETA: 1s - loss: 3.6251 - acc: 0.098 - ETA: 1s - loss: 3.6147 - acc: 0.099 - ETA: 1s - loss: 3.6041 - acc: 0.100 - ETA: 1s - loss: 3.5916 - acc: 0.102 - ETA: 0s - loss: 3.5872 - acc: 0.103 - ETA: 0s - loss: 3.5851 - acc: 0.103 - ETA: 0s - loss: 3.5825 - acc: 0.105 - ETA: 0s - loss: 3.5748 - acc: 0.107 - ETA: 0s - loss: 3.5671 - acc: 0.109 - ETA: 0s - loss: 3.5644 - acc: 0.107 - ETA: 0s - loss: 3.5586 - acc: 0.109 - 9s 4ms/step - loss: 3.5584 - acc: 0.1110 - val_loss: 3.3045 - val_acc: 0.1640\n",
      "Epoch 3/10\n",
      "2108/2108 [==============================] - ETA: 8s - loss: 3.1455 - acc: 0.312 - ETA: 8s - loss: 3.1061 - acc: 0.250 - ETA: 8s - loss: 3.1050 - acc: 0.239 - ETA: 8s - loss: 3.1473 - acc: 0.234 - ETA: 8s - loss: 3.0585 - acc: 0.250 - ETA: 8s - loss: 3.0527 - acc: 0.244 - ETA: 8s - loss: 2.9928 - acc: 0.250 - ETA: 8s - loss: 2.9589 - acc: 0.250 - ETA: 7s - loss: 2.9533 - acc: 0.256 - ETA: 7s - loss: 2.8723 - acc: 0.262 - ETA: 7s - loss: 2.8422 - acc: 0.269 - ETA: 7s - loss: 2.8058 - acc: 0.276 - ETA: 7s - loss: 2.7984 - acc: 0.274 - ETA: 7s - loss: 2.8001 - acc: 0.274 - ETA: 7s - loss: 2.8017 - acc: 0.272 - ETA: 6s - loss: 2.7908 - acc: 0.275 - ETA: 6s - loss: 2.7891 - acc: 0.275 - ETA: 6s - loss: 2.7740 - acc: 0.279 - ETA: 6s - loss: 2.7778 - acc: 0.281 - ETA: 6s - loss: 2.7684 - acc: 0.287 - ETA: 6s - loss: 2.7499 - acc: 0.290 - ETA: 5s - loss: 2.7222 - acc: 0.295 - ETA: 5s - loss: 2.7142 - acc: 0.296 - ETA: 5s - loss: 2.7239 - acc: 0.293 - ETA: 5s - loss: 2.7292 - acc: 0.290 - ETA: 4s - loss: 2.7422 - acc: 0.283 - ETA: 4s - loss: 2.7405 - acc: 0.285 - ETA: 4s - loss: 2.7333 - acc: 0.284 - ETA: 4s - loss: 2.7174 - acc: 0.289 - ETA: 4s - loss: 2.6968 - acc: 0.297 - ETA: 3s - loss: 2.6794 - acc: 0.303 - ETA: 3s - loss: 2.6784 - acc: 0.302 - ETA: 3s - loss: 2.6753 - acc: 0.300 - ETA: 3s - loss: 2.6571 - acc: 0.306 - ETA: 3s - loss: 2.6395 - acc: 0.310 - ETA: 3s - loss: 2.6399 - acc: 0.312 - ETA: 3s - loss: 2.6445 - acc: 0.313 - ETA: 3s - loss: 2.6246 - acc: 0.318 - ETA: 3s - loss: 2.6204 - acc: 0.316 - ETA: 3s - loss: 2.6095 - acc: 0.320 - ETA: 2s - loss: 2.6056 - acc: 0.322 - ETA: 2s - loss: 2.5885 - acc: 0.328 - ETA: 2s - loss: 2.5671 - acc: 0.329 - ETA: 2s - loss: 2.5558 - acc: 0.331 - ETA: 2s - loss: 2.5552 - acc: 0.329 - ETA: 2s - loss: 2.5474 - acc: 0.330 - ETA: 2s - loss: 2.5387 - acc: 0.333 - ETA: 2s - loss: 2.5382 - acc: 0.334 - ETA: 2s - loss: 2.5369 - acc: 0.334 - ETA: 1s - loss: 2.5294 - acc: 0.335 - ETA: 1s - loss: 2.5229 - acc: 0.337 - ETA: 1s - loss: 2.5185 - acc: 0.335 - ETA: 1s - loss: 2.5139 - acc: 0.333 - ETA: 1s - loss: 2.4992 - acc: 0.336 - ETA: 1s - loss: 2.4916 - acc: 0.340 - ETA: 1s - loss: 2.4891 - acc: 0.341 - ETA: 1s - loss: 2.4730 - acc: 0.345 - ETA: 0s - loss: 2.4663 - acc: 0.346 - ETA: 0s - loss: 2.4593 - acc: 0.348 - ETA: 0s - loss: 2.4522 - acc: 0.351 - ETA: 0s - loss: 2.4493 - acc: 0.351 - ETA: 0s - loss: 2.4454 - acc: 0.352 - ETA: 0s - loss: 2.4393 - acc: 0.351 - ETA: 0s - loss: 2.4327 - acc: 0.354 - ETA: 0s - loss: 2.4279 - acc: 0.356 - 9s 4ms/step - loss: 2.4189 - acc: 0.3591 - val_loss: 2.2344 - val_acc: 0.4382\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108/2108 [==============================] - ETA: 8s - loss: 1.7626 - acc: 0.375 - ETA: 8s - loss: 1.8688 - acc: 0.406 - ETA: 8s - loss: 1.8814 - acc: 0.447 - ETA: 8s - loss: 1.9245 - acc: 0.421 - ETA: 8s - loss: 1.9579 - acc: 0.418 - ETA: 8s - loss: 1.8390 - acc: 0.437 - ETA: 8s - loss: 1.6946 - acc: 0.486 - ETA: 8s - loss: 1.7010 - acc: 0.492 - ETA: 7s - loss: 1.6779 - acc: 0.506 - ETA: 7s - loss: 1.7331 - acc: 0.496 - ETA: 7s - loss: 1.6819 - acc: 0.511 - ETA: 7s - loss: 1.7285 - acc: 0.510 - ETA: 7s - loss: 1.7504 - acc: 0.502 - ETA: 7s - loss: 1.7318 - acc: 0.511 - ETA: 7s - loss: 1.7512 - acc: 0.506 - ETA: 7s - loss: 1.7380 - acc: 0.513 - ETA: 6s - loss: 1.7284 - acc: 0.511 - ETA: 6s - loss: 1.7107 - acc: 0.515 - ETA: 6s - loss: 1.6887 - acc: 0.521 - ETA: 5s - loss: 1.6590 - acc: 0.534 - ETA: 5s - loss: 1.6333 - acc: 0.543 - ETA: 5s - loss: 1.6407 - acc: 0.541 - ETA: 4s - loss: 1.6212 - acc: 0.547 - ETA: 4s - loss: 1.6066 - acc: 0.552 - ETA: 4s - loss: 1.6206 - acc: 0.546 - ETA: 4s - loss: 1.5973 - acc: 0.549 - ETA: 4s - loss: 1.5781 - acc: 0.555 - ETA: 4s - loss: 1.5774 - acc: 0.554 - ETA: 4s - loss: 1.5601 - acc: 0.558 - ETA: 4s - loss: 1.5479 - acc: 0.561 - ETA: 4s - loss: 1.5294 - acc: 0.564 - ETA: 4s - loss: 1.5105 - acc: 0.572 - ETA: 4s - loss: 1.4978 - acc: 0.573 - ETA: 3s - loss: 1.4902 - acc: 0.576 - ETA: 3s - loss: 1.4867 - acc: 0.576 - ETA: 3s - loss: 1.4882 - acc: 0.575 - ETA: 3s - loss: 1.4851 - acc: 0.576 - ETA: 3s - loss: 1.4821 - acc: 0.578 - ETA: 3s - loss: 1.4870 - acc: 0.580 - ETA: 3s - loss: 1.4862 - acc: 0.580 - ETA: 3s - loss: 1.4757 - acc: 0.585 - ETA: 3s - loss: 1.4678 - acc: 0.589 - ETA: 2s - loss: 1.4757 - acc: 0.587 - ETA: 2s - loss: 1.4700 - acc: 0.587 - ETA: 2s - loss: 1.4587 - acc: 0.591 - ETA: 2s - loss: 1.4637 - acc: 0.591 - ETA: 2s - loss: 1.4573 - acc: 0.592 - ETA: 2s - loss: 1.4541 - acc: 0.593 - ETA: 2s - loss: 1.4445 - acc: 0.595 - ETA: 2s - loss: 1.4430 - acc: 0.595 - ETA: 1s - loss: 1.4450 - acc: 0.595 - ETA: 1s - loss: 1.4437 - acc: 0.595 - ETA: 1s - loss: 1.4416 - acc: 0.596 - ETA: 1s - loss: 1.4406 - acc: 0.597 - ETA: 1s - loss: 1.4430 - acc: 0.596 - ETA: 1s - loss: 1.4444 - acc: 0.594 - ETA: 1s - loss: 1.4463 - acc: 0.593 - ETA: 0s - loss: 1.4478 - acc: 0.592 - ETA: 0s - loss: 1.4386 - acc: 0.596 - ETA: 0s - loss: 1.4520 - acc: 0.593 - ETA: 0s - loss: 1.4524 - acc: 0.593 - ETA: 0s - loss: 1.4461 - acc: 0.595 - ETA: 0s - loss: 1.4456 - acc: 0.594 - ETA: 0s - loss: 1.4389 - acc: 0.596 - ETA: 0s - loss: 1.4330 - acc: 0.598 - 9s 4ms/step - loss: 1.4365 - acc: 0.5963 - val_loss: 1.5937 - val_acc: 0.5780\n",
      "Epoch 5/10\n",
      "2108/2108 [==============================] - ETA: 8s - loss: 0.8936 - acc: 0.750 - ETA: 8s - loss: 1.0002 - acc: 0.750 - ETA: 8s - loss: 0.9802 - acc: 0.739 - ETA: 8s - loss: 0.9390 - acc: 0.742 - ETA: 8s - loss: 0.9233 - acc: 0.750 - ETA: 8s - loss: 0.9028 - acc: 0.739 - ETA: 8s - loss: 0.9163 - acc: 0.732 - ETA: 8s - loss: 0.9103 - acc: 0.730 - ETA: 8s - loss: 0.9259 - acc: 0.729 - ETA: 8s - loss: 0.9029 - acc: 0.740 - ETA: 7s - loss: 0.9021 - acc: 0.741 - ETA: 7s - loss: 0.9250 - acc: 0.734 - ETA: 6s - loss: 0.9021 - acc: 0.740 - ETA: 6s - loss: 0.9091 - acc: 0.732 - ETA: 6s - loss: 0.8946 - acc: 0.733 - ETA: 5s - loss: 0.8992 - acc: 0.728 - ETA: 5s - loss: 0.8837 - acc: 0.733 - ETA: 5s - loss: 0.9237 - acc: 0.725 - ETA: 5s - loss: 0.9450 - acc: 0.725 - ETA: 4s - loss: 0.9471 - acc: 0.720 - ETA: 4s - loss: 0.9403 - acc: 0.717 - ETA: 4s - loss: 0.9436 - acc: 0.717 - ETA: 4s - loss: 0.9365 - acc: 0.720 - ETA: 4s - loss: 0.9409 - acc: 0.720 - ETA: 4s - loss: 0.9452 - acc: 0.718 - ETA: 4s - loss: 0.9423 - acc: 0.720 - ETA: 4s - loss: 0.9399 - acc: 0.719 - ETA: 4s - loss: 0.9461 - acc: 0.716 - ETA: 4s - loss: 0.9438 - acc: 0.717 - ETA: 3s - loss: 0.9367 - acc: 0.718 - ETA: 3s - loss: 0.9289 - acc: 0.722 - ETA: 3s - loss: 0.9236 - acc: 0.726 - ETA: 3s - loss: 0.9228 - acc: 0.725 - ETA: 3s - loss: 0.9175 - acc: 0.726 - ETA: 3s - loss: 0.9177 - acc: 0.725 - ETA: 3s - loss: 0.9207 - acc: 0.728 - ETA: 3s - loss: 0.9145 - acc: 0.730 - ETA: 3s - loss: 0.9194 - acc: 0.727 - ETA: 3s - loss: 0.9271 - acc: 0.726 - ETA: 3s - loss: 0.9270 - acc: 0.727 - ETA: 2s - loss: 0.9321 - acc: 0.727 - ETA: 2s - loss: 0.9254 - acc: 0.729 - ETA: 2s - loss: 0.9340 - acc: 0.725 - ETA: 2s - loss: 0.9321 - acc: 0.725 - ETA: 2s - loss: 0.9390 - acc: 0.722 - ETA: 2s - loss: 0.9353 - acc: 0.722 - ETA: 2s - loss: 0.9335 - acc: 0.723 - ETA: 2s - loss: 0.9404 - acc: 0.722 - ETA: 1s - loss: 0.9408 - acc: 0.721 - ETA: 1s - loss: 0.9332 - acc: 0.722 - ETA: 1s - loss: 0.9331 - acc: 0.722 - ETA: 1s - loss: 0.9331 - acc: 0.721 - ETA: 1s - loss: 0.9344 - acc: 0.721 - ETA: 1s - loss: 0.9348 - acc: 0.721 - ETA: 1s - loss: 0.9309 - acc: 0.721 - ETA: 0s - loss: 0.9300 - acc: 0.720 - ETA: 0s - loss: 0.9244 - acc: 0.723 - ETA: 0s - loss: 0.9171 - acc: 0.726 - ETA: 0s - loss: 0.9123 - acc: 0.726 - ETA: 0s - loss: 0.9162 - acc: 0.727 - ETA: 0s - loss: 0.9150 - acc: 0.728 - ETA: 0s - loss: 0.9144 - acc: 0.728 - ETA: 0s - loss: 0.9107 - acc: 0.729 - 8s 4ms/step - loss: 0.9086 - acc: 0.7296 - val_loss: 1.3419 - val_acc: 0.6263\n",
      "Epoch 6/10\n",
      "2108/2108 [==============================] - ETA: 7s - loss: 0.4016 - acc: 0.812 - ETA: 8s - loss: 0.5063 - acc: 0.796 - ETA: 8s - loss: 0.5155 - acc: 0.822 - ETA: 8s - loss: 0.5924 - acc: 0.804 - ETA: 8s - loss: 0.5207 - acc: 0.831 - ETA: 9s - loss: 0.5119 - acc: 0.833 - ETA: 8s - loss: 0.4635 - acc: 0.852 - ETA: 8s - loss: 0.4399 - acc: 0.867 - ETA: 7s - loss: 0.4716 - acc: 0.857 - ETA: 7s - loss: 0.4780 - acc: 0.853 - ETA: 6s - loss: 0.4705 - acc: 0.852 - ETA: 6s - loss: 0.4616 - acc: 0.854 - ETA: 6s - loss: 0.4871 - acc: 0.846 - ETA: 5s - loss: 0.4745 - acc: 0.848 - ETA: 5s - loss: 0.4566 - acc: 0.854 - ETA: 5s - loss: 0.4587 - acc: 0.853 - ETA: 4s - loss: 0.4708 - acc: 0.847 - ETA: 4s - loss: 0.4686 - acc: 0.847 - ETA: 4s - loss: 0.4705 - acc: 0.846 - ETA: 4s - loss: 0.4780 - acc: 0.845 - ETA: 4s - loss: 0.4766 - acc: 0.846 - ETA: 4s - loss: 0.4913 - acc: 0.842 - ETA: 4s - loss: 0.4892 - acc: 0.845 - ETA: 4s - loss: 0.4924 - acc: 0.847 - ETA: 4s - loss: 0.4918 - acc: 0.848 - ETA: 4s - loss: 0.4837 - acc: 0.850 - ETA: 4s - loss: 0.4756 - acc: 0.852 - ETA: 4s - loss: 0.4894 - acc: 0.845 - ETA: 4s - loss: 0.4926 - acc: 0.842 - ETA: 4s - loss: 0.4900 - acc: 0.843 - ETA: 4s - loss: 0.4906 - acc: 0.844 - ETA: 3s - loss: 0.4986 - acc: 0.843 - ETA: 3s - loss: 0.4951 - acc: 0.844 - ETA: 3s - loss: 0.4985 - acc: 0.842 - ETA: 3s - loss: 0.4979 - acc: 0.842 - ETA: 3s - loss: 0.5027 - acc: 0.841 - ETA: 3s - loss: 0.5073 - acc: 0.839 - ETA: 3s - loss: 0.5056 - acc: 0.840 - ETA: 3s - loss: 0.5085 - acc: 0.839 - ETA: 3s - loss: 0.5192 - acc: 0.837 - ETA: 2s - loss: 0.5283 - acc: 0.831 - ETA: 2s - loss: 0.5310 - acc: 0.830 - ETA: 2s - loss: 0.5467 - acc: 0.828 - ETA: 2s - loss: 0.5444 - acc: 0.829 - ETA: 2s - loss: 0.5466 - acc: 0.829 - ETA: 2s - loss: 0.5408 - acc: 0.832 - ETA: 2s - loss: 0.5450 - acc: 0.830 - ETA: 1s - loss: 0.5574 - acc: 0.825 - ETA: 1s - loss: 0.5603 - acc: 0.825 - ETA: 1s - loss: 0.5597 - acc: 0.825 - ETA: 1s - loss: 0.5598 - acc: 0.825 - ETA: 1s - loss: 0.5594 - acc: 0.824 - ETA: 1s - loss: 0.5569 - acc: 0.825 - ETA: 1s - loss: 0.5559 - acc: 0.825 - ETA: 1s - loss: 0.5556 - acc: 0.825 - ETA: 1s - loss: 0.5623 - acc: 0.824 - ETA: 0s - loss: 0.5592 - acc: 0.824 - ETA: 0s - loss: 0.5561 - acc: 0.825 - ETA: 0s - loss: 0.5596 - acc: 0.824 - ETA: 0s - loss: 0.5630 - acc: 0.823 - ETA: 0s - loss: 0.5649 - acc: 0.823 - ETA: 0s - loss: 0.5636 - acc: 0.823 - ETA: 0s - loss: 0.5642 - acc: 0.823 - ETA: 0s - loss: 0.5637 - acc: 0.823 - 9s 4ms/step - loss: 0.5641 - acc: 0.8235 - val_loss: 1.2288 - val_acc: 0.6532\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108/2108 [==============================] - ETA: 13s - loss: 0.3964 - acc: 0.90 - ETA: 10s - loss: 0.3782 - acc: 0.89 - ETA: 8s - loss: 0.3367 - acc: 0.8854 - ETA: 7s - loss: 0.3317 - acc: 0.898 - ETA: 6s - loss: 0.3406 - acc: 0.887 - ETA: 6s - loss: 0.4059 - acc: 0.885 - ETA: 5s - loss: 0.3785 - acc: 0.897 - ETA: 5s - loss: 0.3766 - acc: 0.898 - ETA: 5s - loss: 0.3838 - acc: 0.895 - ETA: 5s - loss: 0.3905 - acc: 0.890 - ETA: 5s - loss: 0.3954 - acc: 0.889 - ETA: 6s - loss: 0.3814 - acc: 0.893 - ETA: 6s - loss: 0.3683 - acc: 0.894 - ETA: 6s - loss: 0.3515 - acc: 0.897 - ETA: 5s - loss: 0.3399 - acc: 0.902 - ETA: 5s - loss: 0.3351 - acc: 0.904 - ETA: 5s - loss: 0.3416 - acc: 0.900 - ETA: 5s - loss: 0.3411 - acc: 0.899 - ETA: 5s - loss: 0.3328 - acc: 0.903 - ETA: 5s - loss: 0.3295 - acc: 0.904 - ETA: 5s - loss: 0.3220 - acc: 0.909 - ETA: 5s - loss: 0.3307 - acc: 0.903 - ETA: 5s - loss: 0.3209 - acc: 0.907 - ETA: 5s - loss: 0.3202 - acc: 0.907 - ETA: 5s - loss: 0.3205 - acc: 0.907 - ETA: 5s - loss: 0.3175 - acc: 0.908 - ETA: 4s - loss: 0.3206 - acc: 0.907 - ETA: 4s - loss: 0.3168 - acc: 0.907 - ETA: 4s - loss: 0.3207 - acc: 0.906 - ETA: 4s - loss: 0.3196 - acc: 0.907 - ETA: 4s - loss: 0.3193 - acc: 0.906 - ETA: 4s - loss: 0.3130 - acc: 0.908 - ETA: 4s - loss: 0.3150 - acc: 0.907 - ETA: 4s - loss: 0.3154 - acc: 0.906 - ETA: 3s - loss: 0.3143 - acc: 0.906 - ETA: 3s - loss: 0.3134 - acc: 0.906 - ETA: 3s - loss: 0.3204 - acc: 0.904 - ETA: 3s - loss: 0.3188 - acc: 0.905 - ETA: 3s - loss: 0.3199 - acc: 0.903 - ETA: 3s - loss: 0.3259 - acc: 0.901 - ETA: 2s - loss: 0.3286 - acc: 0.900 - ETA: 2s - loss: 0.3278 - acc: 0.899 - ETA: 2s - loss: 0.3319 - acc: 0.898 - ETA: 2s - loss: 0.3269 - acc: 0.899 - ETA: 2s - loss: 0.3344 - acc: 0.897 - ETA: 2s - loss: 0.3308 - acc: 0.899 - ETA: 2s - loss: 0.3347 - acc: 0.899 - ETA: 2s - loss: 0.3336 - acc: 0.899 - ETA: 2s - loss: 0.3309 - acc: 0.900 - ETA: 1s - loss: 0.3332 - acc: 0.899 - ETA: 1s - loss: 0.3305 - acc: 0.900 - ETA: 1s - loss: 0.3289 - acc: 0.900 - ETA: 1s - loss: 0.3276 - acc: 0.901 - ETA: 1s - loss: 0.3296 - acc: 0.900 - ETA: 1s - loss: 0.3318 - acc: 0.899 - ETA: 1s - loss: 0.3362 - acc: 0.899 - ETA: 1s - loss: 0.3366 - acc: 0.898 - ETA: 0s - loss: 0.3373 - acc: 0.898 - ETA: 0s - loss: 0.3408 - acc: 0.898 - ETA: 0s - loss: 0.3462 - acc: 0.895 - ETA: 0s - loss: 0.3429 - acc: 0.896 - ETA: 0s - loss: 0.3413 - acc: 0.897 - ETA: 0s - loss: 0.3433 - acc: 0.897 - ETA: 0s - loss: 0.3497 - acc: 0.896 - ETA: 0s - loss: 0.3523 - acc: 0.894 - 9s 4ms/step - loss: 0.3539 - acc: 0.8933 - val_loss: 1.3034 - val_acc: 0.6640\n",
      "Epoch 8/10\n",
      "2108/2108 [==============================] - ETA: 3s - loss: 0.3539 - acc: 0.875 - ETA: 3s - loss: 0.3743 - acc: 0.890 - ETA: 3s - loss: 0.2985 - acc: 0.916 - ETA: 3s - loss: 0.2826 - acc: 0.921 - ETA: 3s - loss: 0.2821 - acc: 0.918 - ETA: 3s - loss: 0.2603 - acc: 0.927 - ETA: 3s - loss: 0.2378 - acc: 0.933 - ETA: 3s - loss: 0.2281 - acc: 0.933 - ETA: 3s - loss: 0.2239 - acc: 0.934 - ETA: 3s - loss: 0.2286 - acc: 0.931 - ETA: 3s - loss: 0.2330 - acc: 0.929 - ETA: 4s - loss: 0.2489 - acc: 0.921 - ETA: 4s - loss: 0.2601 - acc: 0.915 - ETA: 4s - loss: 0.2476 - acc: 0.921 - ETA: 4s - loss: 0.2373 - acc: 0.925 - ETA: 4s - loss: 0.2366 - acc: 0.925 - ETA: 4s - loss: 0.2367 - acc: 0.924 - ETA: 4s - loss: 0.2298 - acc: 0.927 - ETA: 4s - loss: 0.2232 - acc: 0.929 - ETA: 4s - loss: 0.2188 - acc: 0.931 - ETA: 4s - loss: 0.2213 - acc: 0.928 - ETA: 4s - loss: 0.2278 - acc: 0.926 - ETA: 4s - loss: 0.2392 - acc: 0.923 - ETA: 4s - loss: 0.2445 - acc: 0.923 - ETA: 4s - loss: 0.2405 - acc: 0.925 - ETA: 4s - loss: 0.2350 - acc: 0.926 - ETA: 4s - loss: 0.2403 - acc: 0.923 - ETA: 4s - loss: 0.2445 - acc: 0.920 - ETA: 4s - loss: 0.2471 - acc: 0.921 - ETA: 4s - loss: 0.2474 - acc: 0.921 - ETA: 4s - loss: 0.2478 - acc: 0.920 - ETA: 4s - loss: 0.2462 - acc: 0.919 - ETA: 3s - loss: 0.2434 - acc: 0.921 - ETA: 3s - loss: 0.2404 - acc: 0.922 - ETA: 3s - loss: 0.2393 - acc: 0.923 - ETA: 3s - loss: 0.2376 - acc: 0.923 - ETA: 3s - loss: 0.2453 - acc: 0.920 - ETA: 3s - loss: 0.2403 - acc: 0.922 - ETA: 2s - loss: 0.2432 - acc: 0.922 - ETA: 2s - loss: 0.2412 - acc: 0.922 - ETA: 2s - loss: 0.2412 - acc: 0.923 - ETA: 2s - loss: 0.2389 - acc: 0.923 - ETA: 2s - loss: 0.2384 - acc: 0.921 - ETA: 2s - loss: 0.2376 - acc: 0.921 - ETA: 2s - loss: 0.2371 - acc: 0.921 - ETA: 2s - loss: 0.2382 - acc: 0.921 - ETA: 2s - loss: 0.2392 - acc: 0.921 - ETA: 1s - loss: 0.2418 - acc: 0.919 - ETA: 1s - loss: 0.2402 - acc: 0.919 - ETA: 1s - loss: 0.2386 - acc: 0.920 - ETA: 1s - loss: 0.2431 - acc: 0.919 - ETA: 1s - loss: 0.2452 - acc: 0.918 - ETA: 1s - loss: 0.2455 - acc: 0.918 - ETA: 1s - loss: 0.2440 - acc: 0.918 - ETA: 1s - loss: 0.2428 - acc: 0.918 - ETA: 1s - loss: 0.2423 - acc: 0.918 - ETA: 1s - loss: 0.2420 - acc: 0.917 - ETA: 0s - loss: 0.2428 - acc: 0.917 - ETA: 0s - loss: 0.2459 - acc: 0.917 - ETA: 0s - loss: 0.2449 - acc: 0.918 - ETA: 0s - loss: 0.2473 - acc: 0.918 - ETA: 0s - loss: 0.2474 - acc: 0.916 - ETA: 0s - loss: 0.2474 - acc: 0.916 - ETA: 0s - loss: 0.2532 - acc: 0.916 - ETA: 0s - loss: 0.2534 - acc: 0.916 - 8s 4ms/step - loss: 0.2539 - acc: 0.9160 - val_loss: 1.3454 - val_acc: 0.6720\n",
      "Epoch 9/10\n",
      "2108/2108 [==============================] - ETA: 3s - loss: 0.0885 - acc: 1.000 - ETA: 3s - loss: 0.0758 - acc: 1.000 - ETA: 3s - loss: 0.0780 - acc: 1.000 - ETA: 3s - loss: 0.1826 - acc: 0.960 - ETA: 5s - loss: 0.1895 - acc: 0.950 - ETA: 5s - loss: 0.1831 - acc: 0.953 - ETA: 6s - loss: 0.1793 - acc: 0.950 - ETA: 6s - loss: 0.1816 - acc: 0.953 - ETA: 6s - loss: 0.1733 - acc: 0.951 - ETA: 6s - loss: 0.1782 - acc: 0.950 - ETA: 6s - loss: 0.1774 - acc: 0.948 - ETA: 6s - loss: 0.1738 - acc: 0.950 - ETA: 6s - loss: 0.1759 - acc: 0.949 - ETA: 6s - loss: 0.1684 - acc: 0.950 - ETA: 6s - loss: 0.1730 - acc: 0.947 - ETA: 6s - loss: 0.1664 - acc: 0.949 - ETA: 6s - loss: 0.1699 - acc: 0.946 - ETA: 6s - loss: 0.1823 - acc: 0.942 - ETA: 6s - loss: 0.1920 - acc: 0.940 - ETA: 5s - loss: 0.1893 - acc: 0.942 - ETA: 5s - loss: 0.1892 - acc: 0.942 - ETA: 5s - loss: 0.1867 - acc: 0.943 - ETA: 5s - loss: 0.1824 - acc: 0.945 - ETA: 5s - loss: 0.1816 - acc: 0.946 - ETA: 5s - loss: 0.1807 - acc: 0.947 - ETA: 5s - loss: 0.1801 - acc: 0.945 - ETA: 5s - loss: 0.1791 - acc: 0.945 - ETA: 5s - loss: 0.1857 - acc: 0.943 - ETA: 4s - loss: 0.1850 - acc: 0.944 - ETA: 4s - loss: 0.1852 - acc: 0.943 - ETA: 4s - loss: 0.1931 - acc: 0.941 - ETA: 4s - loss: 0.1925 - acc: 0.941 - ETA: 4s - loss: 0.1895 - acc: 0.942 - ETA: 3s - loss: 0.1872 - acc: 0.943 - ETA: 3s - loss: 0.1977 - acc: 0.940 - ETA: 3s - loss: 0.1982 - acc: 0.941 - ETA: 3s - loss: 0.1974 - acc: 0.940 - ETA: 3s - loss: 0.2007 - acc: 0.940 - ETA: 3s - loss: 0.2005 - acc: 0.939 - ETA: 2s - loss: 0.1998 - acc: 0.940 - ETA: 2s - loss: 0.1987 - acc: 0.939 - ETA: 2s - loss: 0.1967 - acc: 0.940 - ETA: 2s - loss: 0.1973 - acc: 0.939 - ETA: 2s - loss: 0.1951 - acc: 0.940 - ETA: 2s - loss: 0.1958 - acc: 0.941 - ETA: 2s - loss: 0.1932 - acc: 0.942 - ETA: 2s - loss: 0.1905 - acc: 0.943 - ETA: 1s - loss: 0.1873 - acc: 0.944 - ETA: 1s - loss: 0.1865 - acc: 0.945 - ETA: 1s - loss: 0.1853 - acc: 0.945 - ETA: 1s - loss: 0.1845 - acc: 0.946 - ETA: 1s - loss: 0.1892 - acc: 0.945 - ETA: 1s - loss: 0.1875 - acc: 0.945 - ETA: 1s - loss: 0.1842 - acc: 0.946 - ETA: 1s - loss: 0.1836 - acc: 0.947 - ETA: 1s - loss: 0.1820 - acc: 0.948 - ETA: 1s - loss: 0.1806 - acc: 0.948 - ETA: 0s - loss: 0.1787 - acc: 0.948 - ETA: 0s - loss: 0.1767 - acc: 0.949 - ETA: 0s - loss: 0.1772 - acc: 0.949 - ETA: 0s - loss: 0.1756 - acc: 0.949 - ETA: 0s - loss: 0.1745 - acc: 0.950 - ETA: 0s - loss: 0.1737 - acc: 0.949 - ETA: 0s - loss: 0.1718 - acc: 0.950 - ETA: 0s - loss: 0.1698 - acc: 0.951 - 8s 4ms/step - loss: 0.1694 - acc: 0.9516 - val_loss: 1.5155 - val_acc: 0.6774\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108/2108 [==============================] - ETA: 7s - loss: 0.0291 - acc: 1.000 - ETA: 7s - loss: 0.0748 - acc: 0.984 - ETA: 6s - loss: 0.1860 - acc: 0.937 - ETA: 5s - loss: 0.1631 - acc: 0.937 - ETA: 5s - loss: 0.1595 - acc: 0.943 - ETA: 4s - loss: 0.1490 - acc: 0.942 - ETA: 4s - loss: 0.1796 - acc: 0.942 - ETA: 4s - loss: 0.2060 - acc: 0.941 - ETA: 4s - loss: 0.1876 - acc: 0.947 - ETA: 4s - loss: 0.1718 - acc: 0.953 - ETA: 3s - loss: 0.1726 - acc: 0.946 - ETA: 3s - loss: 0.1709 - acc: 0.947 - ETA: 3s - loss: 0.1619 - acc: 0.951 - ETA: 3s - loss: 0.1543 - acc: 0.953 - ETA: 3s - loss: 0.1532 - acc: 0.952 - ETA: 3s - loss: 0.1517 - acc: 0.951 - ETA: 3s - loss: 0.1477 - acc: 0.952 - ETA: 3s - loss: 0.1432 - acc: 0.953 - ETA: 3s - loss: 0.1383 - acc: 0.955 - ETA: 2s - loss: 0.1384 - acc: 0.953 - ETA: 2s - loss: 0.1371 - acc: 0.950 - ETA: 2s - loss: 0.1349 - acc: 0.953 - ETA: 2s - loss: 0.1323 - acc: 0.953 - ETA: 2s - loss: 0.1352 - acc: 0.953 - ETA: 2s - loss: 0.1361 - acc: 0.953 - ETA: 2s - loss: 0.1467 - acc: 0.951 - ETA: 2s - loss: 0.1454 - acc: 0.950 - ETA: 2s - loss: 0.1422 - acc: 0.952 - ETA: 2s - loss: 0.1417 - acc: 0.952 - ETA: 2s - loss: 0.1383 - acc: 0.954 - ETA: 2s - loss: 0.1366 - acc: 0.954 - ETA: 2s - loss: 0.1388 - acc: 0.955 - ETA: 2s - loss: 0.1360 - acc: 0.956 - ETA: 2s - loss: 0.1350 - acc: 0.956 - ETA: 2s - loss: 0.1333 - acc: 0.957 - ETA: 2s - loss: 0.1321 - acc: 0.957 - ETA: 2s - loss: 0.1315 - acc: 0.956 - ETA: 2s - loss: 0.1283 - acc: 0.958 - ETA: 2s - loss: 0.1260 - acc: 0.959 - ETA: 2s - loss: 0.1233 - acc: 0.960 - ETA: 2s - loss: 0.1215 - acc: 0.961 - ETA: 2s - loss: 0.1247 - acc: 0.960 - ETA: 2s - loss: 0.1242 - acc: 0.960 - ETA: 2s - loss: 0.1261 - acc: 0.960 - ETA: 2s - loss: 0.1254 - acc: 0.960 - ETA: 2s - loss: 0.1235 - acc: 0.961 - ETA: 1s - loss: 0.1232 - acc: 0.961 - ETA: 1s - loss: 0.1213 - acc: 0.962 - ETA: 1s - loss: 0.1204 - acc: 0.962 - ETA: 1s - loss: 0.1207 - acc: 0.961 - ETA: 1s - loss: 0.1202 - acc: 0.962 - ETA: 1s - loss: 0.1194 - acc: 0.962 - ETA: 1s - loss: 0.1182 - acc: 0.962 - ETA: 1s - loss: 0.1172 - acc: 0.963 - ETA: 1s - loss: 0.1201 - acc: 0.961 - ETA: 1s - loss: 0.1185 - acc: 0.962 - ETA: 0s - loss: 0.1169 - acc: 0.963 - ETA: 0s - loss: 0.1193 - acc: 0.962 - ETA: 0s - loss: 0.1206 - acc: 0.962 - ETA: 0s - loss: 0.1199 - acc: 0.963 - ETA: 0s - loss: 0.1202 - acc: 0.962 - ETA: 0s - loss: 0.1194 - acc: 0.962 - ETA: 0s - loss: 0.1204 - acc: 0.962 - ETA: 0s - loss: 0.1211 - acc: 0.962 - ETA: 0s - loss: 0.1201 - acc: 0.962 - 7s 3ms/step - loss: 0.1192 - acc: 0.9625 - val_loss: 1.5737 - val_acc: 0.6962\n",
      "{'val_loss': [4.042423648218954, 3.304515218222013, 2.234381784674942, 1.5936818661228302, 1.3419305329681726, 1.2288178506717886, 1.3033771662301914, 1.3453588081944374, 1.515507032153427, 1.5736857703936997], 'val_acc': [0.018817204341132154, 0.16397849478388346, 0.438172044292573, 0.5779569879654916, 0.6263440873033257, 0.6532258064516129, 0.6639784933418356, 0.6720430113935983, 0.6774193548387096, 0.6962365597806951], 'loss': [4.125022896326922, 3.5583867624091017, 2.4189012835555106, 1.43645317120163, 0.9086092505780751, 0.5641481444324443, 0.3539195938965401, 0.25389876226546415, 0.16940267369914552, 0.11917161072058288], 'acc': [0.02277039850318002, 0.11100569262789595, 0.3591081591665858, 0.5962998100770266, 0.7296015180265655, 0.8235294121040113, 0.8932637574550549, 0.9160341554846212, 0.95161290345201, 0.962523719391289]}\n"
     ]
    }
   ],
   "source": [
    "ganguly.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "feeds=ganguly.fit(x=X_train_arr,y=y_train_arr,epochs=10,validation_data=(X_val_arr,y_val_arr))\n",
    "print(feeds.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the training data is: 0.962523719391289\n",
      "Cross_Validating accuracy is: 0.6962365597806951\n"
     ]
    }
   ],
   "source": [
    "print(\"Final accuracy on the training data is:\",feeds.history['acc'][-1]);\n",
    "print(\"Cross_Validating accuracy is:\",feeds.history['val_acc'][-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with some image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have seen the training accuracy and validation accuracy, we are confident enough to test our output. So I am using an image from our \n",
    "given dataset to check whether it is identified correct. Now since we have trained the model to return a vector. Hence here also the prediction will actually be a vector.\n",
    "We need to find the maximum probability lies on which position. The index of that position is the predicted result. And we can obtain the symbol using the bag of symbol and this index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d209675940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAD8CAYAAAAsX4y/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFYFJREFUeJzt3X+s3XV9x/Hna60FQaUtWoJtTSHeOImJUBtW1BgHyoARWhfIIC7csbqbbG4DXaJl/rGYbIlsRhxxqTZWdzEIVIS1IUzWFPbjHyqtYC0U7AW1vbZSDFCnLCrzvT++70MP7aX3e+/9nHu+33tej+Tk+/1+vp9z7ud7zumrn/M53+/5KCIwM7NyfqvfDTAzm2scrGZmhTlYzcwKc7CamRXmYDUzK8zBamZWWE+CVdIlkp6UNCZpfS/+hplZU6n0eayS5gHfBz4IjAMPA9dExONF/5CZWUP1osd6PjAWEU9HxK+AO4A1Pfg7ZmaNNL8Hj7kUONC1PQ78zrGVJI0AI7n5rh60w8xsKn4aEW8q8UC9CFZNUHbceENEbAQ2AkjydbVm1m8/KvVAvRgKGAeWd20vAw724O+YmTVSL4L1YWBI0lmSFgBXA1t78HfMzBqp+FBARLwk6S+A+4F5wFci4rHSf8fMrKmKn241rUZ4jNXM+m9XRKwq8UC+8srMrDAHq5lZYQ5WM7PCHKxmZoU5WM3MCnOwmpkV5mA1MyvMwWpmVpiD1cysMAermVlhDlYzs8IcrGZmhTlYzcwKc7CamRXmYDUzK2zSYJX0FUmHJe3pKlssaZukfblclOWSdIukMUm7Ja3sZePNzJqoTo/1X4BLjilbD2yPiCFge24DXAoM5W0E2FCmmWZm7TFpsEbEfwHPHVO8BhjN9VFgbVf5rVF5CFgo6cxSjTUza4PpjrGeERGHAHK5JMuXAge66o1nmZnZwCg9maAmKJtwPitJI1TDBWZmc8p0e6zPdD7i5/Jwlo8Dy7vqLQMOTvQAEbExIlaVmrzLzKwpphusW4HhXB8GtnSVX5tnB6wGjnSGDMzMBsWkQwGSbgfeD7xR0jjwt8BngM2S1gH7gauy+n3AZcAY8CJwXQ/abGbWaIqYcAh0dhsh9b8RZjbodpUamvSVV2ZmhTlYzcwKc7CamRXmYDUzK8zBamZWmIPVzKwwB6uZWWEOVjOzwhysZmaFOVjNzApzsJqZFeZgNTMrzMFqZlaYg9XMrDAHq5lZYQ5WM7PCJg1WScslPShpr6THJF2f5YslbZO0L5eLslySbpE0Jmm3pJW9Pggzsyap02N9CfjriHg7sBr4qKRzgPXA9ogYArbnNsClwFDeRoANxVttZtZgkwZrRByKiO/k+v8Ae4GlwBpgNKuNAmtzfQ1wa1QeAhZ2ZnQ1MxsEUxpjlbQCOA/YAZzRmYE1l0uy2lLgQNfdxrPs2McakbRT0s6pN9vMrLkmnaW1Q9LrgG8CN0TEzyS9atUJyo6bLDAiNgIb87E9maCZzRm1eqySXkMVqrdFxN1Z/EznI34uD2f5OLC86+7LgINlmmtm1nx1zgoQsAnYGxGf69q1FRjO9WFgS1f5tXl2wGrgSGfIwMxsECjixJ/CJb0X+G/ge8BvsvhvqMZZNwNvAfYDV0XEcxnEXwAuAV4ErouIE46jeijAzBpgV0SsKvFAkwbrbHCwmlkDFAtWX3llZlaYg9XMrLDap1tZu9QZ4jnBKXNmNgPusc4xEVErVDt1zaw8B+scMp2gdLialedgnSNmEpAOV7OyHKxzQIlgdLialeNgtZc5XM3KcLCamRXmYG250r1M91rNZs7BamZWmIPVjuNeq9nMOFjNzApzsJqZFeZgNTMrrM4MAidL+rak70p6TNKns/wsSTsk7ZN0p6QFWX5Sbo/l/hW9PYTB1qsfUvE4q9n01emx/hK4MCLeCZwLXJJTrtwE3BwRQ8DzwLqsvw54PiLeCtyc9czMBsakwRqVn+fma/IWwIXAXVk+CqzN9TW5Te6/SP59ulZyr9VseurO0jpP0qNUM7FuA54CXoiIl7LKOLA015cCBwBy/xHg9Akec0TSTkknnA/LzKxtagVrRPxfRJxLNZX1+cDbJ6qWy4l6p8d1fSJiY0SsKjXHzCDzBwKzZpnSWQER8QLwH8BqYKGkzgwEy4CDuT4OLAfI/acBz5VorM0+DweYTV2dswLeJGlhrr8W+ACwF3gQuDKrDQNbcn1rbpP7Hwj/6+w591rNmqPOnFdnAqOS5lEF8eaIuFfS48Adkv4OeATYlPU3AV+TNEbVU726B+22WRQRDm6zKVATOpOS+t+IOaJXr6eD1QbArlLf+fjKKzOzwhysVksTPtmYtYWDdY7xR3az/nOwmpkVVuesALOeOtEwg3vg1kbusc5BbQmjiJh07LZOHbOmcbDOQU0PoumEZdOPyaybg9Vm1UwC0uFqbeFgtVqaMrzgcLU2cLDarCkVig5XazoH6xzj0DHrPwerzQoHvg0SB6u1koPamszBapNqyhdXZm3hYJ1D3Isza4bawZoTCj4i6d7cPkvSDkn7JN0paUGWn5TbY7l/RW+abm3hwLdBM5Ue6/VUU7J03ATcHBFDwPPAuixfBzwfEW8Fbs56ZmYDo+7018uA3we+nNsCLgTuyiqjwNpcX5Pb5P6L5EG61mrqS9fUdplB/R7r54FPAL/J7dOBFyLipdweB5bm+lLgAEDuP5L1X0HSiKSdknZOs+1mZo1UZ5bWy4HDEbGru3iCqlFj39GCiI0RsarUHDODrqnjmE1tl1kv1fk91vcAV0i6DDgZeANVD3ahpPnZK10GHMz648ByYFzSfOA0qtlazcwGwqQ91oi4MSKWRcQKqqmsH4iIDwMPAldmtWFgS65vzW1y/wPhbksreRzTbHpmch7rJ4GPSxqjGkPdlOWbgNOz/OPA+pk10eyVHPjWdGpCZ1JS/xvRYr16DWcaYE1tl9mr2FXqOx9feWVmVpiD1SbkXqHZ9DlYrVUc+NYGDtaWa8IYeb/5ObCmqXMeq9mU9TLsJnrsY8vcs7V+co/VWqVuYLsXa/3kYLXjzJXeXkQ4YK0vHKwt5tCox8+TzTaPsdqUOajMTszBaseZi8EZEXNmiMOaz0MBZmaFOVhbai72Ks3mCgerDQz/Z2SzxcHaQg4Is2bzl1ct4kA1a4e6s7T+UNL3JD3amfxP0mJJ2yTty+WiLJekWySNSdotaWUvD2BQOFTN2mMqQwG/GxHndv0Q7Hpge0QMAds5OlPApcBQ3kaADaUaazYTPt3KZstMxljXAKO5Pgqs7Sq/NSoPUU06eOYM/s7Ac2/VrF3qBmsA/y5pl6SRLDsjIg4B5HJJli8FDnTddzzLXkHSiKSdnaEFM7O5ou6XV++JiIOSlgDbJD1xgroTfd46rssVERuBjeA5r6z3PAxgs6lWjzUiDubyMHAPcD7wTOcjfi4PZ/VxYHnX3ZcBB0s12GyqHKo22yYNVkmnSnp9Zx24GNgDbAWGs9owsCXXtwLX5tkBq4EjnSEDM7NBUGco4Azgnvxffz7w9Yj4lqSHgc2S1gH7gauy/n3AZcAY8CJwXfFWm9Xgnqr1i5rwjbPHWE+sCa9R2zhUbRp2dZ1OOiO+8srmFAeqNYGD1eYEB6o1iYPVWschak3nYG0BSQM7zuoQtTbyzwa2hAPGrD3cY22RJvVcJwr60m3zfybWVg7Wlul1uDrMzGbOwdpCnfCbSsD2OjCb0pM2awIHa4u5d2nWTP7yysysMAermVlhDlZrLI/bWls5WM3MCnOwmpkV5mC1InyGgtlRtYJV0kJJd0l6QtJeSRdIWixpm6R9uVyUdSXpFkljknZLWtnbQzAza5a6PdZ/Ar4VEb8NvBPYC6wHtkfEELA9twEuBYbyNgJsKNpiM7OGqzPn1RuA9wGbACLiVxHxArAGGM1qo8DaXF8D3BqVh4CFnUkHzcwGQZ0e69nAs8BXJT0i6cs5qeAZnUkCc7kk6y8FDnTdfzzLXkHSiKSdknbO6AjMzBqmTrDOB1YCGyLiPOAXHP3YP5GJvsU47oTEiNgYEatKzTFjZtYUdYJ1HBiPiB25fRdV0D7T+Yify8Nd9Zd33X8ZcLBMc23Q+CIBa6NJgzUifgIckPS2LLoIeBzYCgxn2TCwJde3Atfm2QGrgSOdIQOb23zKlVml7q9b/SVwm6QFwNPAdVShvFnSOmA/cFXWvQ+4DBgDXsy6ZmYDQ034qCWp/42wInrxfnJP2GbJrlLf+fjKKzOzwhys1nhN+FRlNhUOVjOzwhysVpTHQ80crNYSHg6wNnGwmpkV5mA1MyvMwWpmVpiD1Yrr1RdYHme1tnCwmpkV5mC1VnGv1drAwWo94fNZbZA5WK113Gu1pnOwmpkV5mC1nunlcIB7rdZkdWZpfZukR7tuP5N0g6TFkrZJ2pfLRVlfkm6RNCZpt6SVvT8MM7PmqDM1y5MRcW5EnAu8i2pWgHuoJhTcHhFDwHaOTjB4KTCUtxFgQy8abuZeqzXVVIcCLgKeiogfAWuA0SwfBdbm+hrg1qg8BCzsTDpog8dnB9ggmmqwXg3cnutndCYJzOWSLF8KHOi6z3iWmRXnXqs1Ue1gzYkErwC+MVnVCcqOe/dLGpG0U9LOum0wM2uDqfRYLwW+ExHP5PYznY/4uTyc5ePA8q77LQMOHvtgEbExIlaVmrzLmsvDATZophKs13B0GABgKzCc68PAlq7ya/PsgNXAkc6QgZnZIKg1/bWkU6jGTc+OiCNZdjqwGXgLsB+4KiKeU9U9+QJwCdUZBNdFxAk/7nv668HQq/FQ94itkGLTX9cK1l5zsA6OXrzfHKxWSLFg9ZVX1moOVWsiB6uZWWEOVptV7mHaIHCw2qwrFa4OaWsqB6v1xUxD0aFqTeZgtb6Zbjg6VK3p5ve7ATbYOiFZ83zqXjfHrAgHqzXCiQLWgWpt42C1RnGI2lzgMVYzs8IcrGZmhTlYzcwKc7CamRXmYDUzK8zBamZWWK1glfQxSY9J2iPpdkknSzpL0g5J+yTdmXNiIemk3B7L/St6eQBmZk0zabBKWgr8FbAqIt4BzKOarfUm4OaIGAKeB9blXdYBz0fEW4Gbs56Z2cCoOxQwH3itpPnAKcAh4ELgrtw/CqzN9TW5Te6/SD7r28wGyKTBGhE/Bj5LNa/VIeAIsAt4ISJeymrjwNJcX0o1Pxa5/whwetlmm5k1V52hgEVUvdCzgDcDp1JNhX2szkXeE/VOj7sAXNKIpJ2STjjRoJlZ29QZCvgA8IOIeDYifg3cDbwbWJhDAwDLgIO5Pg4sB8j9pwHPHfugEbExIlaVmrzLzKwp6gTrfmC1pFNyrPQi4HHgQeDKrDMMbMn1rblN7n8gmjAVrJnZLKk1/bWkTwN/CLwEPAJ8hGos9Q5gcZb9UUT8UtLJwNeA86h6qldHxNOTPL6D18z6rdj017WCtdccrGbWAMWC1VdemZkV5mA1MyvMwWpmVpiD1cysMAermVlhDlYzs8IcrGZmhTlYzcwKc7CamRXmYDUzK8zBamZWmIPVzKwwB6uZWWEOVjOzwhysZmaFOVjNzAqrFaySrpe0R9Jjkm7IssWStknal8tFWS5Jt0gak7Rb0speHoCZWdPUmaX1HcCfAucD7wQulzQErAe2R8QQsD23oZrBdShvI8CGHrTbzKyx6vRY3w48FBEvRsRLwH8CH6KaEns064wCa3N9DXBrVB6ims31zMLtNjNrrPmTV2EP8PeSTgf+F7gM2AmcERGHACLikKQlWX8pcKDr/uNZdqj7QSWNUPVoAX6Zf6fN3gj8tN+NmAG3v7/a3n5o/zG8rdQDTRqsEbFX0k3ANuDnwHepZmt9NZroYSZ43I3ARgBJO0tN4tUvbT8Gt7+/2t5+aP8xSNpZ6rFqfXkVEZsiYmVEvI9qSut9wDOdj/i5PJzVx4HlXXdfBhws1WAzs6are1bAkly+BfgD4HZgKzCcVYaBLbm+Fbg2zw5YDRzpDBmYmQ2COmOsAN/MMdZfAx+NiOclfQbYLGkdsB+4KuveRzUOOwa8CFxX4/E3Tq3ZjdT2Y3D7+6vt7Yf2H0Ox9iviuOFPMzObAV95ZWZWmIPVzKywvgerpEskPZmXwK6f/B6zT9JySQ9K2puX9V6f5a26rFfSPEmPSLo3t8+StCPbf6ekBVl+Um6P5f4V/Wx3tmmhpLskPZGvwwUtfP4/lu+fPZJul3Ryk18DSV+RdFjSnq6yKT/nkoaz/j5JwxP9rVk+hn/M99FuSfdIWti178Y8hicl/V5X+dRyKiL6dgPmAU8BZwMLqM6RPaefbXqVdp4JrMz11wPfB84B/gFYn+XrgZty/TLg36jO6V0N7Oj3MWS7Pg58Hbg3tzcDV+f6F4E/y/U/B76Y61cDdzag7aPAR3J9AbCwTc8/1UUyPwBe2/Xc/3GTXwPgfcBKYE9X2ZSec2Ax8HQuF+X6oj4fw8XA/Fy/qesYzskMOgk4K7Np3nRyqt9vtguA+7u2bwRu7GebarZ7C/BB4EngzCw7E3gy178EXNNV/+V6fWzzMqrfdLgQuDf/Afy06w328msB3A9ckOvzs5762PY3ZCjpmPI2Pf+dKxIX53N6L/B7TX8NgBXHhNKUnnPgGuBLXeWvqNePYzhm34eA23L9FfnTeQ2mk1P9Hgp4tctfGys/kp0H7OCYy3qByS7r7afPA58AfpPbpwMvRPX7D/DKNr7c/tx/JOv3y9nAs8BXcyjjy5JOpUXPf0T8GPgs1amJh6ie01205zXomOpz3rjX4hh/QtXThoLH0O9grXX5a1NIeh3wTeCGiPjZiapOUNa345J0OXA4InZ1F09QNWrs64f5VB/nNkTEecAvOPprahNpWvvJscg1VB8x3wycSvVLcMdq6mswmVdrb2OPQ9KnqC7Pv61TNEG1aR1Dv4O1NZe/SnoNVajeFhF3Z3FbLut9D3CFpB8Cd1ANB3ye6pfHOheJdLfx5fbn/tOoLmXul3FgPCJ25PZdVEHblucf4APADyLi2Yj4NXA38G7a8xp0TPU5b+JrQX6Jdjnw4cjP9xQ8hn4H68PAUH4zuoBqkH5rn9t0HEkCNgF7I+JzXbtacVlvRNwYEcsiYgXVc/xARHwYeBC4Mqsd2/7OcV2Z9fvWy4iInwAHJHV+fegi4HFa8vyn/cBqSafk+6lzDK14DbpM9Tm/H7hY0qLstV+cZX0j6RLgk8AVEfFi166twNV5RsZZVL8p/W2mk1OzPRg+weDxZVTfsj8FfKrf7XmVNr6Xquu/G3g0b5dRjXltp/pRmu3A4qwv4J/zmL4HrOr3MXQdy/s5elbA2fnGGQO+AZyU5Sfn9ljuP7sB7T6X6ucqdwP/SvUNc6uef+DTwBNUP5H5Napvnxv7GlD9JsghqkvZx4F103nOqcYxx/J2XQOOYYxqzLTzb/mLXfU/lcfwJHBpV/mUcsqXtJqZFdbvoQAzsznHwWpmVpiD1cysMAermVlhDlYzs8IcrGZmhTlYzcwK+3+wyqkKpz1V1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=cv2.imread(\"D://datasets//IIIT_D//train//Sample005//img005-001.png\",cv2.IMREAD_GRAYSCALE)/255\n",
    "img1=np.reshape((cv2.resize(img,(50,50))),(50,50,1))\n",
    "plt.imshow(img,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 with accuracy of 0.998936\n"
     ]
    }
   ],
   "source": [
    "predict=ganguly.predict(np.array([img1]))[0]\n",
    "acc=max(predict)\n",
    "val=np.argmax(predict)\n",
    "print(bag[val],\"with accuracy of\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d260a902b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=cv2.imread(\"D://datasets//IIIT_D//train//Sample015//img015-028.png\",cv2.IMREAD_GRAYSCALE)/255\n",
    "img1=np.reshape((cv2.resize(img,(50,50))),(50,50,1))\n",
    "plt.imshow(img,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E with accuracy of 0.99801946\n"
     ]
    }
   ],
   "source": [
    "predict=ganguly.predict(np.array([img1]))[0]\n",
    "acc=max(predict)\n",
    "val=np.argmax(predict)\n",
    "print(bag[val],\"with accuracy of\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d260af2a58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=cv2.imread(\"D://datasets//IIIT_D//train//Sample019//img019-028.png\",cv2.IMREAD_GRAYSCALE)/255\n",
    "img1=np.reshape((cv2.resize(img,(50,50))),(50,50,1))\n",
    "plt.imshow(img,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I with accuracy of 0.9845489\n"
     ]
    }
   ],
   "source": [
    "predict=ganguly.predict(np.array([img1]))[0]\n",
    "acc=max(predict)\n",
    "val=np.argmax(predict)\n",
    "print(bag[val],\"with accuracy of\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d260b56b38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAD8CAYAAAAsX4y/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFH1JREFUeJzt3WGsnNV95/Hvb3GAJG1imxZEbUeAYqWJKgVcK+s0VdSFNAU2imkFKlFWeFl3Le12d5NmpdZsXqwi7UpltypZ1BWpFdKaiBIoSdYWSptFht32DW7skhLAob5JWnxrFycCnG1ZpWHz3xdzbhjsa+5c+9w7M77fjzR6nuc8Z2bOM3P985kzzzMnVYUkqZ9/NO4GSNK5xmCVpM4MVknqzGCVpM4MVknqzGCVpM6WJFiTXJvkmSQzSXYuxXNI0qRK7/NYk5wH/CXw88As8BXgQ1X1dNcnkqQJtRQ91ncBM1X1zar6B+BzwNYleB5JmkirluAx1wFHhrZngX98cqUkO4AdbfOnl6AdkrQY36mqH+/xQEsRrJmn7JTxhqraBewCSOJ1tZLG7a97PdBSDAXMAhuGttcDR5fgeSRpIi1FsH4F2Jjk8iTnAzcDe5fgeSRpInUfCqiql5P8G+DLwHnAZ6rqqd7PI0mTqvvpVmfUCMdYJY3fwara3OOBvPJKkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjpbMFiTfCbJ8SRPDpWtTfJwksNtuaaVJ8mdSWaSPJFk01I2XpIm0Sg91t8Hrj2pbCewr6o2AvvaNsB1wMZ22wHc1aeZkjQ9FgzWqvoT4PmTircCu9v6buCGofJ7auAxYHWSS3s1VpKmwZmOsV5SVccA2vLiVr4OODJUb7aVSdKK0XsywcxTNu98Vkl2MBgukKRzypn2WJ+b+4jflsdb+SywYajeeuDofA9QVbuqanOvybskaVKcabDuBba19W3AnqHyW9rZAVuAE3NDBpK0Uiw4FJDkPuDngB9LMgv8R+A3gQeSbAeeBW5q1b8EXA/MAC8Bty5BmyVpoqVq3iHQ5W1EMv5GSFrpDvYamvTKK0nqzGCVpM4MVknqzGCVpM4MVknqzGCVpM4MVknqzGCVpM4MVknqzGCVpM4MVknqzGCVpM4MVknqzGCVpM4MVknqzGCVpM4WDNYkG5I8muRQkqeSfKSVr03ycJLDbbmmlSfJnUlmkjyRZNNSH4QkTZJReqwvA/++qt4ObAF+Nck7gJ3AvqraCOxr2wDXARvbbQdwV/dWS9IEWzBYq+pYVf15W/8/wCFgHbAV2N2q7QZuaOtbgXtq4DFg9dyMrpK0EixqjDXJZcBVwH7gkrkZWNvy4lZtHXBk6G6zrezkx9qR5ECSA4tvtiRNrgVnaZ2T5EeAzwMfrarvJjlt1XnKTpkssKp2AbvaYzuZoKRzxkg91iSvYxCq91bVF1rxc3Mf8dvyeCufBTYM3X09cLRPcyVp8o1yVkCAu4FDVfXbQ7v2Atva+jZgz1D5Le3sgC3AibkhA0laCVL12p/Ck/ws8KfA14AftOL/wGCc9QHgLcCzwE1V9XwL4t8BrgVeAm6tqtccR3UoQNIEOFhVm3s80ILBuhwMVkkToFuweuWVJHVmsEpSZwarJHVmsEpSZwarJHVmsEpSZwarJHVmsEpSZwarJHVmsEpSZwarJHVmsEpSZwarJHVmsEpSZwarJHU2ygwCFyb5syR/keSpJJ9o5Zcn2Z/kcJL7k5zfyi9o2zNt/2VLewiSNFlG6bF+D7i6qt4JXAlc26ZcuR24o6o2Ai8A21v97cALVfVW4I5WT5JWjAWDtQb+rm2+rt0KuBp4sJXvBm5o61vbNm3/NXmNKV0l6Vwz6iyt5yX5KoOZWB8GvgG8WFUvtyqzwLq2vg44AtD2nwAumucxdyQ5kOQ158OSpGkzUrBW1f+rqisZTGX9LuDt81Vry/l6p6fMaVVVu6pqc685ZiRpUizqrICqehH4X8AWYHWSVW3XeuBoW58FNgC0/W8Gnu/RWEmaBqOcFfDjSVa39dcD7wMOAY8CN7Zq24A9bX1v26btf6QmYSpYTZyqmvcmTbtVC1fhUmB3kvMYBPEDVfVQkqeBzyX5T8DjwN2t/t3AZ5PMMOip3rwE7dYUWyg85/b7naemVSahh5Bk/I3Qsljs35vhqmV0sNd3Pl55pWVzJv+JT8J//NJiGayS1NkoY6zSWTubnmdVLXpI4OTnc0hBy8lg1TnldAE+XG7Iaqk5FKCpMEqPd9ReseO2WmoGq84Jiw1Lw1VLyWCVpM4MVi2LHuOao4yf9ng86WwZrJLUmcGqqWIvU9PAYNWy8TQnrRQGq6aOvVZNOoNVkjozWLWseg0HzPVa7b1qEhmsWnaOtepcN3KwtgkFH0/yUNu+PMn+JIeT3J/k/FZ+QdueafsvW5qma6Wzt6pJtZge60cYTMky53bgjqraCLwAbG/l24EXquqtwB2tniStGKNOf70e+KfAp9t2gKuBB1uV3cANbX1r26btvyZ+9tNJ/JPQuWzUHusngV8HftC2LwJerKqX2/YssK6trwOOALT9J1r9V0myI8mBJAfOsO2SNJFGmaX1A8Dxqjo4XDxP1Rph3ysFVbuqanOvOWY0fey16lw1yg9dvwf4YJLrgQuBNzHowa5Osqr1StcDR1v9WWADMJtkFfBmBrO1ShPFYNdSWbDHWlW3VdX6qrqMwVTWj1TVh4FHgRtbtW3Anra+t23T9j9Sfn2r0zDcdC46m/NYfwP4WJIZBmOod7fyu4GLWvnHgJ1n10SpPwNdSymT0JlMMv5GaKyW8+/QUNVpHOz1nY9XXklSZwarJoK9SJ1LDFatKAa4loPBqhXDUNVyMVg1MQw+nSsMVq0IhraWk8GqibIUAWioarkZrJLUmcGqidOzh2lvVeNgsOqcZahqXAxWTSRDUdPMYNXEOptwNZg1TgarJtpiAzKJoaqxG+WHrqWxmgvK1/oFLMNUk8Rg1dQwPDUtRp2l9a+SfC3JV+cm/0uyNsnDSQ635ZpWniR3JplJ8kSSTUt5AJI0aRYzxvpPqurKoR+C3Qnsq6qNwD5emSngOmBju+0A7urVWEmaBmfz5dVWYHdb3w3cMFR+Tw08xmDSwUvP4nkkaaqMGqwF/M8kB5PsaGWXVNUxgLa8uJWvA44M3Xe2lb1Kkh1JDswNLUjSuWLUL6/eU1VHk1wMPJzk669Rd75vGE75OreqdgG7wDmvJJ1bRuqxVtXRtjwOfBF4F/Dc3Ef8tjzeqs8CG4buvh442qvBkjTpFgzWJG9M8qNz68D7gSeBvcC2Vm0bsKet7wVuaWcHbAFOzA0ZSNJKMMpQwCXAF9s5hKuAP6iqP07yFeCBJNuBZ4GbWv0vAdcDM8BLwK3dWy1JEyzLOZ/7aRvhGKuk8Ts4dDrpWfG3AiSpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWps5GCNcnqJA8m+XqSQ0nenWRtkoeTHG7LNa1uktyZZCbJE0k2Le0hSNJkGbXH+t+AP66qnwTeCRwCdgL7qmojsK9tA1wHbGy3HcBdXVssSRNulDmv3gS8F7gboKr+oapeBLYCu1u13cANbX0rcE8NPAasnpt0UJJWglF6rFcA3wZ+L8njST7dJhW8ZG6SwLa8uNVfBxwZuv9sK3uVJDuSHEhy4KyOQJImzCjBugrYBNxVVVcBf88rH/vnk3nKTpnTqqp2VdXmXnPMSNKkGCVYZ4HZqtrfth9kELTPzX3Eb8vjQ/U3DN1/PXC0T3MlafItGKxV9bfAkSRva0XXAE8De4FtrWwbsKet7wVuaWcHbAFOzA0ZSNJKsGrEev8WuDfJ+cA3gVsZhPIDSbYDzwI3tbpfAq4HZoCXWl1JWjFSdcrw5/I3Ihl/IyStdAd7fefjlVeS1JnBKkmdGayS1JnBKkmdGayS1JnBKkmdGayS1JnBKkmdGayS1JnBKkmdGayS1JnBKkmdGayS1JnBKkmdGayS1Nkos7S+LclXh27fTfLRJGuTPJzkcFuuafWT5M4kM0meSLJp6Q9DkibHKFOzPFNVV1bVlcBPM5gV4IsMJhTcV1UbgX28MsHgdcDGdtsB3LUUDZekSbXYoYBrgG9U1V8DW4HdrXw3cENb3wrcUwOPAavnJh2UpJVgscF6M3BfW79kbpLAtry4la8DjgzdZ7aVSdKKMHKwtokEPwj84UJV5yk7ZU6rJDuSHEhyYNQ2SNI0WEyP9Trgz6vqubb93NxH/LY83spngQ1D91sPHD35wapqV1Vt7jV5lyRNisUE64d4ZRgAYC+wra1vA/YMld/Szg7YApyYGzKQpJVgpOmvk7yBwbjpFVV1opVdBDwAvAV4Fripqp5PEuB3gGsZnEFwa1W95sd9p7+WNAG6TX89UrAuNYNV0gToFqxeeSVJnRmsktSZwSpJnRmsktSZwSpJnRmsktSZwSpJnRmsktSZwSpJnRmsktSZwSpJnRmsktSZwSpJnRmsktSZwSpJnY0UrEl+LclTSZ5Mcl+SC5NcnmR/ksNJ7m9zYpHkgrY90/ZftpQHIEmTZsFgTbIO+HfA5qr6KeA8BrO13g7cUVUbgReA7e0u24EXquqtwB2tniStGKMOBawCXp9kFfAG4BhwNfBg278buKGtb23btP3XtOlaJGlFWDBYq+pvgN9iMK/VMeAEcBB4sapebtVmgXVtfR2D+bFo+08AF/VttiRNrlGGAtYw6IVeDvwE8EYGU2GfbG7eqvl6p6fMaZVkR5IDSV5zokFJmjajDAW8D/hWVX27qr4PfAH4GWB1GxoAWA8cbeuzwAaAtv/NwPMnP2hV7aqqzb0m75KkSTFKsD4LbEnyhjZWeg3wNPAocGOrsw3Y09b3tm3a/kdqEqaClaRlMtL010k+Afwy8DLwOPArDMZSPwesbWX/rKq+l+RC4LPAVQx6qjdX1TcXeHyDV9K4dZv+eqRgXWoGq6QJ0C1YvfJKkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWpM4NVkjozWCWps5GCNclHkjyZ5KkkH21la5M8nORwW65p5UlyZ5KZJE8k2bSUByBJk2aUWVp/CviXwLuAdwIfSLIR2Ansq6qNwL62DYMZXDe22w7griVotyRNrFF6rG8HHquql6rqZeB/A7/IYErs3a3ObuCGtr4VuKcGHmMwm+ulndstSRNr1cJVeBL4z0kuAv4vcD1wALikqo4BVNWxJBe3+uuAI0P3n21lx4YfNMkOBj1agO+155lmPwZ8Z9yNOAu2f7ymvf0w/cfwtl4PtGCwVtWhJLcDDwN/B/wFg9laTyfzPcw8j7sL2AWQ5ECvSbzGZdqPwfaP17S3H6b/GJIc6PVYI315VVV3V9WmqnovgymtDwPPzX3Eb8vjrfossGHo7uuBo70aLEmTbtSzAi5uy7cAvwTcB+wFtrUq24A9bX0vcEs7O2ALcGJuyECSVoJRxlgBPt/GWL8P/GpVvZDkN4EHkmwHngVuanW/xGAcdgZ4Cbh1hMfftbhmT6RpPwbbP17T3n6Y/mPo1v5UnTL8KUk6C155JUmdGayS1NnYgzXJtUmeaZfA7lz4HssvyYYkjyY51C7r/Ugrn6rLepOcl+TxJA+17cuT7G/tvz/J+a38grY90/ZfNs52tzatTvJgkq+39+HdU/j6/1r7+3kyyX1JLpzk9yDJZ5IcT/LkUNmiX/Mk21r9w0m2zfdcy3wM/7X9HT2R5ItJVg/tu60dwzNJfmGofHE5VVVjuwHnAd8ArgDOZ3CO7DvG2abTtPNSYFNb/1HgL4F3AP8F2NnKdwK3t/XrgT9icE7vFmD/uI+htetjwB8AD7XtB4Cb2/qngH/V1v818Km2fjNw/wS0fTfwK239fGD1NL3+DC6S+Rbw+qHX/p9P8nsAvBfYBDw5VLao1xxYC3yzLde09TVjPob3A6va+u1Dx/COlkEXAJe3bDrvTHJq3H9s7wa+PLR9G3DbONs0Yrv3AD8PPANc2souBZ5p678LfGio/g/rjbHN6xn8psPVwEPtH8B3hv7AfvheAF8G3t3WV7V6GWPb39RCKSeVT9PrP3dF4tr2mj4E/MKkvwfAZSeF0qJec+BDwO8Olb+q3jiO4aR9vwjc29ZflT9z78GZ5NS4hwJOd/nrxGofya4C9nPSZb3AQpf1jtMngV8HftC2LwJerMHvP8Cr2/jD9rf9J1r9cbkC+Dbwe20o49NJ3sgUvf5V9TfAbzE4NfEYg9f0INPzHsxZ7Gs+ce/FSf4Fg542dDyGcQfrSJe/TookPwJ8HvhoVX33tarOUza240ryAeB4VR0cLp6nao2wbxxWMfg4d1dVXQX8Pa/8mtp8Jq39tLHIrQw+Yv4E8EYGvwR3skl9DxZyuvZO7HEk+TiDy/PvnSuap9oZHcO4g3VqLn9N8joGoXpvVX2hFU/LZb3vAT6Y5K+AzzEYDvgkg18em7tIZLiNP2x/2/9mBpcyj8ssMFtV+9v2gwyCdlpef4D3Ad+qqm9X1feBLwA/w/S8B3MW+5pP4ntB+xLtA8CHq32+p+MxjDtYvwJsbN+Mns9gkH7vmNt0iiQB7gYOVdVvD+2aist6q+q2qlpfVZcxeI0fqaoPA48CN7ZqJ7d/7rhubPXH1suoqr8FjiSZ+/Wha4CnmZLXv3kW2JLkDe3vae4YpuI9GLLY1/zLwPuTrGm99ve3srFJci3wG8AHq+qloV17gZvbGRmXM/hN6T/jTHJquQfD5xk8vp7Bt+zfAD4+7vacpo0/y6Dr/wTw1Xa7nsGY1z4GP0qzD1jb6gf47+2YvgZsHvcxDB3Lz/HKWQFXtD+cGeAPgQta+YVte6btv2IC2n0lg5+rfAL4Hwy+YZ6q1x/4BPB1Bj+R+VkG3z5P7HvA4DdBjjG4lH0W2H4mrzmDccyZdrt1Ao5hhsGY6dy/5U8N1f94O4ZngOuGyheVU17SKkmdjXsoQJLOOQarJHVmsEpSZwarJHVmsEpSZwarJHVmsEpSZ/8fVO0HNag4eh4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=cv2.imread(\"D://datasets//IIIT_D//train//Sample058//img058-008.png\",cv2.IMREAD_GRAYSCALE)/255\n",
    "img1=np.reshape((cv2.resize(img,(50,50))),(50,50,1))\n",
    "plt.imshow(img,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v with accuracy of 0.94126296\n"
     ]
    }
   ],
   "source": [
    "predict=ganguly.predict(np.array([img1]))[0]\n",
    "acc=max(predict)\n",
    "val=np.argmax(predict)\n",
    "print(bag[val],\"with accuracy of\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganguly.save('IIIT_D_ganguly_subpart_a.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
