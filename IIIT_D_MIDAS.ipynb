{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D,Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D://datasets//IIIT_D//train\";\n",
    "fol=os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=list(),list();\n",
    "size=len(fol);\n",
    "bag={0:'0',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'A',11:'B',12:'C',13:'D',14:'E',15:'F',16:'G',17:'H',\n",
    "    18:'I',19:'J',20:'K',21:'L',22:'M',23:'N',24:'O',25:'P',26:'Q',27:'R',28:'S',29:'T',30:'U',31:'V',32:'W',33:'X',34:'Y',\n",
    "    35:'Z',36:'a',37:'b',38:'c',39:'d',40:'e',41:'f',42:'g',43:'h',44:'i',45:'j',46:'k',47:'l',48:'m',\n",
    "     49:'n',50:'o',51:'p',52:'q',53:'r',54:'s',55:'t',56:'u',57:'v',58:'w',59:'x',60:'y',61:'z'};\n",
    "def one_hot(val,size):\n",
    "    a=np.array([0]*size);\n",
    "    a[val]=1;\n",
    "    return a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21c42d99898>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=cv2.imread(\"D://datasets//IIIT_D//train//Sample005//img005-001.png\",cv2.IMREAD_GRAYSCALE)/255\n",
    "img1=np.reshape((cv2.resize(img,(50,50))),(50,50,1))\n",
    "plt.imshow(img,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef001e26d8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:30,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for val,i in tqdm(enumerate(fol)):\n",
    "    path_n=os.path.join(path,i);\n",
    "    for img_n in os.listdir(path_n):\n",
    "        img=cv2.imread(os.path.join(path_n,img_n),cv2.IMREAD_GRAYSCALE)/255\n",
    "        X.append((np.reshape(cv2.resize(img,(50,50)),(50,50,1))))\n",
    "        y.append(one_hot(val,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[100][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.15, random_state=42)\n",
    "X_train_arr=np.array(X_train)\n",
    "X_val_arr=np.array(X_val)\n",
    "y_train_arr=np.array(y_train)\n",
    "y_val_arr=np.array(y_val)\n",
    "_,h,w,d=X_train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr_new=np.reshape(X_train_arr,(1860,50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(248, kernel_size=5, activation=\"relu\", input_shape=(50, 50, 1..., padding=\"same\")`\n",
      "  \n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(62, kernel_size=3, activation=\"relu\", padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 50, 50, 248)       6448      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 25, 25, 248)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 25, 25, 62)        138446    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 12, 12, 62)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8928)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 62)                553598    \n",
      "=================================================================\n",
      "Total params: 698,492\n",
      "Trainable params: 698,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(248, kernel_size=5, activation='relu',border_mode='same', input_shape=(h,w,d)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(62, kernel_size=3, activation='relu',border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(62, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# model=Sequential()\n",
    "model.add(Convolution2D(62, (5, 5), activation='relu',border_mode='same',input_shape=(h,w,d)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(124, (5, 5), activation='relu',border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "'''model.add(Convolution2D(124, (5, 5), activation='relu',border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))'''\n",
    "model.add(Convolution2D(62, (5, 5), activation='relu',border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "'''model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))'''\n",
    "model.add(Dense(62, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(124, kernel_size=(3, 3), activation='relu', input_shape=(h,w,d)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(248, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(400, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(248, activation='relu'))\n",
    "model.add(Dense(124, activation='relu'))\n",
    "model.add(Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2108 samples, validate on 372 samples\n",
      "Epoch 1/10\n",
      "2108/2108 [==============================] - ETA: 1:00 - loss: 4.1432 - acc: 0.0000e+0 - ETA: 20s - loss: 4.1829 - acc: 0.0104    - ETA: 13s - loss: 4.1654 - acc: 0.01 - ETA: 9s - loss: 4.1555 - acc: 0.0179 - ETA: 7s - loss: 4.1515 - acc: 0.017 - ETA: 6s - loss: 4.1489 - acc: 0.014 - ETA: 5s - loss: 4.1448 - acc: 0.012 - ETA: 4s - loss: 4.1434 - acc: 0.010 - ETA: 4s - loss: 4.1399 - acc: 0.014 - ETA: 3s - loss: 4.1387 - acc: 0.018 - ETA: 3s - loss: 4.1365 - acc: 0.019 - ETA: 3s - loss: 4.1338 - acc: 0.021 - ETA: 2s - loss: 4.1333 - acc: 0.021 - ETA: 2s - loss: 4.1324 - acc: 0.019 - ETA: 2s - loss: 4.1308 - acc: 0.022 - ETA: 2s - loss: 4.1290 - acc: 0.024 - ETA: 1s - loss: 4.1278 - acc: 0.022 - ETA: 1s - loss: 4.1254 - acc: 0.025 - ETA: 1s - loss: 4.1217 - acc: 0.028 - ETA: 1s - loss: 4.1177 - acc: 0.028 - ETA: 1s - loss: 4.1120 - acc: 0.029 - ETA: 1s - loss: 4.1074 - acc: 0.028 - ETA: 1s - loss: 4.1064 - acc: 0.027 - ETA: 0s - loss: 4.1034 - acc: 0.027 - ETA: 0s - loss: 4.0971 - acc: 0.028 - ETA: 0s - loss: 4.0942 - acc: 0.028 - ETA: 0s - loss: 4.0846 - acc: 0.030 - ETA: 0s - loss: 4.0760 - acc: 0.032 - ETA: 0s - loss: 4.0688 - acc: 0.032 - ETA: 0s - loss: 4.0549 - acc: 0.035 - ETA: 0s - loss: 4.0350 - acc: 0.038 - ETA: 0s - loss: 4.0286 - acc: 0.041 - ETA: 0s - loss: 4.0106 - acc: 0.047 - 3s 2ms/step - loss: 4.0043 - acc: 0.0470 - val_loss: 3.5474 - val_acc: 0.1425\n",
      "Epoch 2/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 3.0980 - acc: 0.250 - ETA: 1s - loss: 3.2115 - acc: 0.218 - ETA: 1s - loss: 3.2692 - acc: 0.187 - ETA: 1s - loss: 3.2430 - acc: 0.200 - ETA: 1s - loss: 3.1771 - acc: 0.229 - ETA: 1s - loss: 3.1275 - acc: 0.233 - ETA: 1s - loss: 3.1135 - acc: 0.226 - ETA: 1s - loss: 3.0758 - acc: 0.235 - ETA: 1s - loss: 3.0613 - acc: 0.242 - ETA: 1s - loss: 3.0255 - acc: 0.254 - ETA: 1s - loss: 2.9951 - acc: 0.261 - ETA: 1s - loss: 2.9558 - acc: 0.269 - ETA: 1s - loss: 2.9338 - acc: 0.276 - ETA: 1s - loss: 2.9221 - acc: 0.278 - ETA: 1s - loss: 2.9076 - acc: 0.283 - ETA: 1s - loss: 2.9128 - acc: 0.282 - ETA: 1s - loss: 2.9137 - acc: 0.284 - ETA: 0s - loss: 2.9000 - acc: 0.284 - ETA: 0s - loss: 2.8914 - acc: 0.284 - ETA: 0s - loss: 2.8734 - acc: 0.289 - ETA: 0s - loss: 2.8661 - acc: 0.289 - ETA: 0s - loss: 2.8576 - acc: 0.288 - ETA: 0s - loss: 2.8403 - acc: 0.289 - ETA: 0s - loss: 2.8357 - acc: 0.293 - ETA: 0s - loss: 2.8213 - acc: 0.294 - ETA: 0s - loss: 2.8086 - acc: 0.297 - ETA: 0s - loss: 2.7788 - acc: 0.303 - ETA: 0s - loss: 2.7688 - acc: 0.309 - ETA: 0s - loss: 2.7582 - acc: 0.314 - ETA: 0s - loss: 2.7365 - acc: 0.320 - ETA: 0s - loss: 2.7246 - acc: 0.324 - ETA: 0s - loss: 2.7209 - acc: 0.323 - ETA: 0s - loss: 2.7124 - acc: 0.326 - 2s 1ms/step - loss: 2.7124 - acc: 0.3254 - val_loss: 2.6737 - val_acc: 0.3522\n",
      "Epoch 3/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 2.0827 - acc: 0.500 - ETA: 1s - loss: 1.7993 - acc: 0.572 - ETA: 1s - loss: 1.8036 - acc: 0.581 - ETA: 1s - loss: 1.9122 - acc: 0.531 - ETA: 1s - loss: 1.8985 - acc: 0.524 - ETA: 1s - loss: 1.9168 - acc: 0.531 - ETA: 1s - loss: 1.8946 - acc: 0.536 - ETA: 1s - loss: 1.8843 - acc: 0.533 - ETA: 1s - loss: 1.8286 - acc: 0.546 - ETA: 1s - loss: 1.8451 - acc: 0.542 - ETA: 1s - loss: 1.8589 - acc: 0.538 - ETA: 1s - loss: 1.8227 - acc: 0.547 - ETA: 1s - loss: 1.8275 - acc: 0.545 - ETA: 1s - loss: 1.7975 - acc: 0.549 - ETA: 1s - loss: 1.8017 - acc: 0.546 - ETA: 1s - loss: 1.8154 - acc: 0.540 - ETA: 1s - loss: 1.8129 - acc: 0.536 - ETA: 0s - loss: 1.8225 - acc: 0.537 - ETA: 0s - loss: 1.8412 - acc: 0.533 - ETA: 0s - loss: 1.8556 - acc: 0.528 - ETA: 0s - loss: 1.8525 - acc: 0.527 - ETA: 0s - loss: 1.8421 - acc: 0.525 - ETA: 0s - loss: 1.8570 - acc: 0.520 - ETA: 0s - loss: 1.8482 - acc: 0.523 - ETA: 0s - loss: 1.8501 - acc: 0.521 - ETA: 0s - loss: 1.8413 - acc: 0.523 - ETA: 0s - loss: 1.8351 - acc: 0.525 - ETA: 0s - loss: 1.8270 - acc: 0.529 - ETA: 0s - loss: 1.8226 - acc: 0.529 - ETA: 0s - loss: 1.8022 - acc: 0.535 - ETA: 0s - loss: 1.7902 - acc: 0.536 - ETA: 0s - loss: 1.8068 - acc: 0.533 - ETA: 0s - loss: 1.8115 - acc: 0.535 - 2s 1ms/step - loss: 1.8085 - acc: 0.5346 - val_loss: 2.3676 - val_acc: 0.4247\n",
      "Epoch 4/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 1.2459 - acc: 0.687 - ETA: 1s - loss: 1.2823 - acc: 0.656 - ETA: 1s - loss: 1.3483 - acc: 0.662 - ETA: 1s - loss: 1.4227 - acc: 0.629 - ETA: 1s - loss: 1.3888 - acc: 0.642 - ETA: 1s - loss: 1.3383 - acc: 0.656 - ETA: 1s - loss: 1.4148 - acc: 0.634 - ETA: 1s - loss: 1.4001 - acc: 0.635 - ETA: 1s - loss: 1.3936 - acc: 0.637 - ETA: 1s - loss: 1.4168 - acc: 0.629 - ETA: 1s - loss: 1.4283 - acc: 0.622 - ETA: 1s - loss: 1.4232 - acc: 0.622 - ETA: 1s - loss: 1.4077 - acc: 0.626 - ETA: 1s - loss: 1.3972 - acc: 0.628 - ETA: 1s - loss: 1.3734 - acc: 0.632 - ETA: 1s - loss: 1.3585 - acc: 0.639 - ETA: 1s - loss: 1.3718 - acc: 0.633 - ETA: 0s - loss: 1.3744 - acc: 0.631 - ETA: 0s - loss: 1.3790 - acc: 0.626 - ETA: 0s - loss: 1.3712 - acc: 0.625 - ETA: 0s - loss: 1.3625 - acc: 0.627 - ETA: 0s - loss: 1.3619 - acc: 0.629 - ETA: 0s - loss: 1.3607 - acc: 0.629 - ETA: 0s - loss: 1.3569 - acc: 0.630 - ETA: 0s - loss: 1.3573 - acc: 0.632 - ETA: 0s - loss: 1.3493 - acc: 0.634 - ETA: 0s - loss: 1.3404 - acc: 0.635 - ETA: 0s - loss: 1.3451 - acc: 0.638 - ETA: 0s - loss: 1.3391 - acc: 0.637 - ETA: 0s - loss: 1.3472 - acc: 0.634 - ETA: 0s - loss: 1.3610 - acc: 0.630 - ETA: 0s - loss: 1.3604 - acc: 0.628 - ETA: 0s - loss: 1.3560 - acc: 0.629 - 2s 1ms/step - loss: 1.3530 - acc: 0.6305 - val_loss: 2.3571 - val_acc: 0.4462\n",
      "Epoch 5/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 0.7723 - acc: 0.843 - ETA: 1s - loss: 0.8099 - acc: 0.770 - ETA: 1s - loss: 0.8983 - acc: 0.737 - ETA: 1s - loss: 0.9728 - acc: 0.732 - ETA: 1s - loss: 1.0000 - acc: 0.732 - ETA: 1s - loss: 1.1084 - acc: 0.701 - ETA: 1s - loss: 1.1516 - acc: 0.685 - ETA: 1s - loss: 1.1449 - acc: 0.687 - ETA: 1s - loss: 1.1362 - acc: 0.694 - ETA: 1s - loss: 1.1641 - acc: 0.685 - ETA: 1s - loss: 1.1599 - acc: 0.686 - ETA: 1s - loss: 1.1609 - acc: 0.683 - ETA: 1s - loss: 1.1447 - acc: 0.688 - ETA: 1s - loss: 1.1196 - acc: 0.691 - ETA: 1s - loss: 1.1176 - acc: 0.692 - ETA: 1s - loss: 1.1073 - acc: 0.693 - ETA: 1s - loss: 1.1009 - acc: 0.695 - ETA: 0s - loss: 1.1057 - acc: 0.691 - ETA: 0s - loss: 1.1023 - acc: 0.693 - ETA: 0s - loss: 1.1080 - acc: 0.693 - ETA: 0s - loss: 1.1005 - acc: 0.694 - ETA: 0s - loss: 1.1101 - acc: 0.690 - ETA: 0s - loss: 1.1042 - acc: 0.693 - ETA: 0s - loss: 1.0943 - acc: 0.693 - ETA: 0s - loss: 1.0896 - acc: 0.695 - ETA: 0s - loss: 1.0947 - acc: 0.694 - ETA: 0s - loss: 1.0835 - acc: 0.698 - ETA: 0s - loss: 1.0798 - acc: 0.699 - ETA: 0s - loss: 1.0795 - acc: 0.697 - ETA: 0s - loss: 1.0761 - acc: 0.699 - ETA: 0s - loss: 1.0786 - acc: 0.699 - ETA: 0s - loss: 1.0726 - acc: 0.700 - ETA: 0s - loss: 1.0754 - acc: 0.700 - 2s 1ms/step - loss: 1.0685 - acc: 0.7021 - val_loss: 2.2593 - val_acc: 0.5081\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108/2108 [==============================] - ETA: 2s - loss: 0.6978 - acc: 0.843 - ETA: 1s - loss: 0.6456 - acc: 0.833 - ETA: 1s - loss: 0.7727 - acc: 0.800 - ETA: 1s - loss: 0.8242 - acc: 0.785 - ETA: 1s - loss: 0.7793 - acc: 0.784 - ETA: 1s - loss: 0.8369 - acc: 0.767 - ETA: 1s - loss: 0.8323 - acc: 0.776 - ETA: 1s - loss: 0.8097 - acc: 0.783 - ETA: 1s - loss: 0.8220 - acc: 0.788 - ETA: 1s - loss: 0.8256 - acc: 0.778 - ETA: 1s - loss: 0.8371 - acc: 0.769 - ETA: 1s - loss: 0.8618 - acc: 0.764 - ETA: 1s - loss: 0.8372 - acc: 0.772 - ETA: 1s - loss: 0.8354 - acc: 0.770 - ETA: 1s - loss: 0.8407 - acc: 0.772 - ETA: 1s - loss: 0.8265 - acc: 0.775 - ETA: 1s - loss: 0.8267 - acc: 0.775 - ETA: 0s - loss: 0.8361 - acc: 0.770 - ETA: 0s - loss: 0.8309 - acc: 0.772 - ETA: 0s - loss: 0.8414 - acc: 0.766 - ETA: 0s - loss: 0.8477 - acc: 0.767 - ETA: 0s - loss: 0.8491 - acc: 0.766 - ETA: 0s - loss: 0.8562 - acc: 0.764 - ETA: 0s - loss: 0.8716 - acc: 0.760 - ETA: 0s - loss: 0.8664 - acc: 0.760 - ETA: 0s - loss: 0.8596 - acc: 0.763 - ETA: 0s - loss: 0.8686 - acc: 0.763 - ETA: 0s - loss: 0.8706 - acc: 0.761 - ETA: 0s - loss: 0.8731 - acc: 0.762 - ETA: 0s - loss: 0.8706 - acc: 0.762 - ETA: 0s - loss: 0.8699 - acc: 0.761 - ETA: 0s - loss: 0.8682 - acc: 0.761 - ETA: 0s - loss: 0.8719 - acc: 0.758 - 2s 1ms/step - loss: 0.8722 - acc: 0.7585 - val_loss: 2.3090 - val_acc: 0.5027\n",
      "Epoch 7/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 0.9745 - acc: 0.750 - ETA: 1s - loss: 0.6788 - acc: 0.833 - ETA: 1s - loss: 0.7046 - acc: 0.818 - ETA: 1s - loss: 0.6521 - acc: 0.830 - ETA: 1s - loss: 0.6900 - acc: 0.812 - ETA: 1s - loss: 0.6749 - acc: 0.821 - ETA: 1s - loss: 0.6657 - acc: 0.826 - ETA: 1s - loss: 0.6421 - acc: 0.833 - ETA: 1s - loss: 0.6322 - acc: 0.832 - ETA: 1s - loss: 0.6269 - acc: 0.827 - ETA: 1s - loss: 0.6398 - acc: 0.821 - ETA: 1s - loss: 0.6369 - acc: 0.820 - ETA: 1s - loss: 0.6284 - acc: 0.820 - ETA: 1s - loss: 0.6360 - acc: 0.818 - ETA: 1s - loss: 0.6443 - acc: 0.819 - ETA: 1s - loss: 0.6463 - acc: 0.818 - ETA: 1s - loss: 0.6510 - acc: 0.818 - ETA: 0s - loss: 0.6575 - acc: 0.815 - ETA: 0s - loss: 0.6579 - acc: 0.813 - ETA: 0s - loss: 0.6582 - acc: 0.813 - ETA: 0s - loss: 0.6620 - acc: 0.811 - ETA: 0s - loss: 0.6687 - acc: 0.811 - ETA: 0s - loss: 0.6746 - acc: 0.810 - ETA: 0s - loss: 0.6839 - acc: 0.808 - ETA: 0s - loss: 0.6848 - acc: 0.808 - ETA: 0s - loss: 0.6859 - acc: 0.807 - ETA: 0s - loss: 0.6784 - acc: 0.810 - ETA: 0s - loss: 0.6863 - acc: 0.808 - ETA: 0s - loss: 0.6855 - acc: 0.808 - ETA: 0s - loss: 0.6837 - acc: 0.808 - ETA: 0s - loss: 0.6854 - acc: 0.807 - ETA: 0s - loss: 0.6899 - acc: 0.805 - ETA: 0s - loss: 0.6934 - acc: 0.803 - 2s 1ms/step - loss: 0.6953 - acc: 0.8036 - val_loss: 2.5395 - val_acc: 0.5027\n",
      "Epoch 8/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 0.4099 - acc: 0.843 - ETA: 1s - loss: 0.4237 - acc: 0.864 - ETA: 1s - loss: 0.5248 - acc: 0.837 - ETA: 1s - loss: 0.5525 - acc: 0.839 - ETA: 1s - loss: 0.5399 - acc: 0.854 - ETA: 1s - loss: 0.5396 - acc: 0.852 - ETA: 1s - loss: 0.5242 - acc: 0.855 - ETA: 1s - loss: 0.5097 - acc: 0.860 - ETA: 1s - loss: 0.5084 - acc: 0.862 - ETA: 1s - loss: 0.5060 - acc: 0.863 - ETA: 1s - loss: 0.4971 - acc: 0.864 - ETA: 1s - loss: 0.4911 - acc: 0.864 - ETA: 1s - loss: 0.5020 - acc: 0.860 - ETA: 1s - loss: 0.4965 - acc: 0.862 - ETA: 1s - loss: 0.5008 - acc: 0.864 - ETA: 1s - loss: 0.5047 - acc: 0.861 - ETA: 1s - loss: 0.5133 - acc: 0.858 - ETA: 0s - loss: 0.5105 - acc: 0.858 - ETA: 0s - loss: 0.5171 - acc: 0.854 - ETA: 0s - loss: 0.5335 - acc: 0.850 - ETA: 0s - loss: 0.5307 - acc: 0.852 - ETA: 0s - loss: 0.5510 - acc: 0.845 - ETA: 0s - loss: 0.5553 - acc: 0.844 - ETA: 0s - loss: 0.5681 - acc: 0.840 - ETA: 0s - loss: 0.5710 - acc: 0.839 - ETA: 0s - loss: 0.5683 - acc: 0.840 - ETA: 0s - loss: 0.5672 - acc: 0.840 - ETA: 0s - loss: 0.5753 - acc: 0.836 - ETA: 0s - loss: 0.5765 - acc: 0.834 - ETA: 0s - loss: 0.5780 - acc: 0.834 - ETA: 0s - loss: 0.5724 - acc: 0.833 - ETA: 0s - loss: 0.5784 - acc: 0.831 - ETA: 0s - loss: 0.5810 - acc: 0.829 - 2s 1ms/step - loss: 0.5821 - acc: 0.8287 - val_loss: 2.5865 - val_acc: 0.5349\n",
      "Epoch 9/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 0.3085 - acc: 0.875 - ETA: 2s - loss: 0.5067 - acc: 0.833 - ETA: 1s - loss: 0.4982 - acc: 0.856 - ETA: 1s - loss: 0.5115 - acc: 0.843 - ETA: 1s - loss: 0.4715 - acc: 0.861 - ETA: 1s - loss: 0.4747 - acc: 0.858 - ETA: 1s - loss: 0.4587 - acc: 0.865 - ETA: 1s - loss: 0.4655 - acc: 0.862 - ETA: 1s - loss: 0.4794 - acc: 0.867 - ETA: 1s - loss: 0.4702 - acc: 0.868 - ETA: 1s - loss: 0.4622 - acc: 0.872 - ETA: 1s - loss: 0.4548 - acc: 0.873 - ETA: 1s - loss: 0.4554 - acc: 0.875 - ETA: 1s - loss: 0.4622 - acc: 0.870 - ETA: 1s - loss: 0.4497 - acc: 0.872 - ETA: 1s - loss: 0.4521 - acc: 0.874 - ETA: 1s - loss: 0.4534 - acc: 0.873 - ETA: 0s - loss: 0.4701 - acc: 0.870 - ETA: 0s - loss: 0.4684 - acc: 0.869 - ETA: 0s - loss: 0.4630 - acc: 0.870 - ETA: 0s - loss: 0.4668 - acc: 0.868 - ETA: 0s - loss: 0.4619 - acc: 0.869 - ETA: 0s - loss: 0.4594 - acc: 0.868 - ETA: 0s - loss: 0.4555 - acc: 0.869 - ETA: 0s - loss: 0.4569 - acc: 0.867 - ETA: 0s - loss: 0.4651 - acc: 0.864 - ETA: 0s - loss: 0.4601 - acc: 0.866 - ETA: 0s - loss: 0.4659 - acc: 0.863 - ETA: 0s - loss: 0.4710 - acc: 0.861 - ETA: 0s - loss: 0.4672 - acc: 0.862 - ETA: 0s - loss: 0.4653 - acc: 0.863 - ETA: 0s - loss: 0.4686 - acc: 0.862 - ETA: 0s - loss: 0.4639 - acc: 0.863 - 2s 1ms/step - loss: 0.4622 - acc: 0.8643 - val_loss: 2.6235 - val_acc: 0.5108\n",
      "Epoch 10/10\n",
      "2108/2108 [==============================] - ETA: 2s - loss: 0.3456 - acc: 0.906 - ETA: 1s - loss: 0.4126 - acc: 0.885 - ETA: 1s - loss: 0.3939 - acc: 0.875 - ETA: 1s - loss: 0.3828 - acc: 0.883 - ETA: 1s - loss: 0.3414 - acc: 0.895 - ETA: 1s - loss: 0.3466 - acc: 0.894 - ETA: 1s - loss: 0.3336 - acc: 0.896 - ETA: 1s - loss: 0.3322 - acc: 0.897 - ETA: 1s - loss: 0.3280 - acc: 0.900 - ETA: 1s - loss: 0.3497 - acc: 0.898 - ETA: 1s - loss: 0.3600 - acc: 0.895 - ETA: 1s - loss: 0.3463 - acc: 0.899 - ETA: 1s - loss: 0.3439 - acc: 0.900 - ETA: 1s - loss: 0.3409 - acc: 0.899 - ETA: 1s - loss: 0.3468 - acc: 0.899 - ETA: 1s - loss: 0.3548 - acc: 0.897 - ETA: 1s - loss: 0.3544 - acc: 0.896 - ETA: 0s - loss: 0.3586 - acc: 0.894 - ETA: 0s - loss: 0.3525 - acc: 0.897 - ETA: 0s - loss: 0.3561 - acc: 0.896 - ETA: 0s - loss: 0.3521 - acc: 0.897 - ETA: 0s - loss: 0.3531 - acc: 0.897 - ETA: 0s - loss: 0.3599 - acc: 0.894 - ETA: 0s - loss: 0.3597 - acc: 0.894 - ETA: 0s - loss: 0.3608 - acc: 0.893 - ETA: 0s - loss: 0.3672 - acc: 0.894 - ETA: 0s - loss: 0.3670 - acc: 0.892 - ETA: 0s - loss: 0.3659 - acc: 0.891 - ETA: 0s - loss: 0.3671 - acc: 0.890 - ETA: 0s - loss: 0.3693 - acc: 0.891 - ETA: 0s - loss: 0.3725 - acc: 0.889 - ETA: 0s - loss: 0.3693 - acc: 0.890 - ETA: 0s - loss: 0.3692 - acc: 0.891 - 2s 1ms/step - loss: 0.3694 - acc: 0.8918 - val_loss: 2.6926 - val_acc: 0.5457\n",
      "{'val_loss': [3.547398644108926, 2.673736197974092, 2.367599509095633, 2.3571109656364686, 2.2592656304759364, 2.308966798167075, 2.5395049228463122, 2.5864735059840704, 2.6234820978615874, 2.6925577758460917], 'val_acc': [0.14247311831962678, 0.3521505376344086, 0.42473118407751925, 0.44623655913978494, 0.5080645174108526, 0.5026881707611904, 0.5026881733248311, 0.5349462359182297, 0.5107526868902227, 0.5456989234493624], 'loss': [4.004317248342612, 2.7124184277297423, 1.8084806651725263, 1.3530208878996703, 1.068515631121069, 0.8721675725770404, 0.6952589628139981, 0.5821209295424836, 0.46220375408031455, 0.3694466565659648], 'acc': [0.046963946890276796, 0.325426944971537, 0.5346299808550152, 0.630455408195843, 0.702087286640616, 0.7585388992045364, 0.8036053128667755, 0.8287476280834914, 0.8643263755984731, 0.8918406070975244]}\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history=model.fit(x=X_train_arr,y=y_train_arr,epochs=10,validation_data=(X_val_arr,y_val_arr))\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 with accuracy of 0.97220796\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict(np.array([img1]))[0]\n",
    "acc=max(predict)\n",
    "val=np.argmax(predict)\n",
    "print(bag[val],\"with accuracy of\",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
